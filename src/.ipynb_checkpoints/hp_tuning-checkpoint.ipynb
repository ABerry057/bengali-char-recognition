{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jason/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/Jason/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/Jason/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/Jason/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/Jason/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/Jason/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "import time, gc\n",
    "import cv2\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import clone_model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = os.path.dirname(os.getcwd())\n",
    "\n",
    "def get_dummies(df):\n",
    "    cols = []\n",
    "    for col in df:\n",
    "        cols.append(pd.get_dummies(df[col].astype(str)))\n",
    "    return pd.concat(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_SIZE=64\n",
    "global IMG_X_SIZE\n",
    "IMG_X_SIZE = 87\n",
    "global IMG_Y_SIZE\n",
    "IMG_Y_SIZE = 106\n",
    "global N_CHANNELS\n",
    "N_CHANNELS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the preprocessed data for fitting in the model\n",
    "# this is for GCP or local\n",
    "proc_img_0 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_0.parquet\").to_pandas()\n",
    "proc_img_1 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_1.parquet\").to_pandas()\n",
    "proc_img_2 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_2.parquet\").to_pandas()\n",
    "proc_img_3 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_3.parquet\").to_pandas()\n",
    "train_images = pd.concat([proc_img_0, proc_img_1, proc_img_2, proc_img_3])\n",
    "train_images.drop(columns=['image_id'],inplace=True)\n",
    "del proc_img_0\n",
    "del proc_img_1\n",
    "del proc_img_2\n",
    "del proc_img_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN takes images in shape `(batch_size, h, w, channels)`, so reshape the images\n",
    "train_images = train_images.values.reshape(-1, IMG_X_SIZE, IMG_Y_SIZE, N_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(parent_directory+\"/data/train.csv\")\n",
    "Y_train_root = pd.get_dummies(train_labels['grapheme_root']).values\n",
    "Y_train_vowel = pd.get_dummies(train_labels['vowel_diacritic']).values\n",
    "Y_train_consonant = pd.get_dummies(train_labels['consonant_diacritic']).values\n",
    "del train_labels\n",
    "# print(f'Training images: {train_images.shape}')\n",
    "# print(f'Training labels root: {Y_train_root.shape}')\n",
    "# print(f'Training labels vowel: {Y_train_vowel.shape}')\n",
    "# print(f'Training labels consonants: {Y_train_consonant.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below this should take around 5 minutes\n",
    "x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant \\\n",
    "    = train_test_split(train_images, Y_train_root, Y_train_vowel, Y_train_consonant, test_size=0.3, random_state=666)\n",
    "del train_images\n",
    "x_val, x_test, y_val_root, y_test_root, y_val_vowel, y_test_vowel, y_val_consonant, y_test_consonant \\\n",
    "    = train_test_split(x_test, y_test_root, y_test_vowel, y_test_consonant, test_size=0.33, random_state=666)\n",
    "# print(f'x_train size: {x_train.shape}')\n",
    "# print(f'x_val size: {x_val.shape}')\n",
    "# print(f'x_test size: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n",
    "\n",
    "    def flow(self,\n",
    "             x,\n",
    "             y=None,\n",
    "             batch_size=32,\n",
    "             shuffle=True,\n",
    "             sample_weight=None,\n",
    "             seed=None,\n",
    "             save_to_dir=None,\n",
    "             save_prefix='',\n",
    "             save_format='png',\n",
    "             subset=None):\n",
    "\n",
    "        targets = None\n",
    "        target_lengths = {}\n",
    "        ordered_outputs = []\n",
    "        for output, target in y.items():\n",
    "            if targets is None:\n",
    "                targets = target\n",
    "            else:\n",
    "                targets = np.concatenate((targets, target), axis=1)\n",
    "            target_lengths[output] = target.shape[1]\n",
    "            ordered_outputs.append(output)\n",
    "\n",
    "\n",
    "        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n",
    "                                         shuffle=shuffle):\n",
    "            target_dict = {}\n",
    "            i = 0\n",
    "            for output in ordered_outputs:\n",
    "                target_length = target_lengths[output]\n",
    "                target_dict[output] = flowy[:, i: i + target_length]\n",
    "                i += target_length\n",
    "\n",
    "            yield flowx, target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data generator (should take two minutes)\n",
    "# Data augmentation for creating more training data\n",
    "datagen = MultiOutputDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.15, # Randomly zoom image \n",
    "    width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "# This will just calculate parameters required to augment the given data. This won't perform any augmentations\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Not going to use exponential anymore after realizing it sucks\n",
    "\"\"\"\n",
    "# need to edit these when we run the actual model and not doing hyperparameter tuning\n",
    "# initial_learning_rate = 0.01\n",
    "# decay_steps = 5 # this would be more like 10 or 20, since we'll be running more epochs\n",
    "# decay_rate = 0.1\n",
    "# learning_rate_exp_root = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#         initial_learning_rate = initial_learning_rate, decay_steps = decay_steps, decay_rate=decay_rate, name=\"lr_expD_root\")\n",
    "# learning_rate_exp_vowel = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#         initial_learning_rate = initial_learning_rate, decay_steps = decay_steps, decay_rate=decay_rate, name=\"lr_expD_vowel\")\n",
    "# learning_rate_exp_consonant = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#         initial_learning_rate = initial_learning_rate, decay_steps = decay_steps, decay_rate=decay_rate, name=\"lr_expD_consonant\")\n",
    "# LR_scheduler_exp_root = tf.keras.callbacks.LearningRateScheduler(learning_rate_exp_root)\n",
    "# LR_scheduler_exp_vowel = tf.keras.callbacks.LearningRateScheduler(learning_rate_exp_vowel)\n",
    "# LR_scheduler_exp_consonant = tf.keras.callbacks.LearningRateScheduler(learning_rate_exp_consonant)\n",
    "\n",
    "# def exponential_decay_fn(epoch):\n",
    "#     return 0.5 * 0.1 **(epoch / 3) # 1st var is initial lr, 2nd is decay_rate, 3rd is decay_steps, i think\n",
    "# lr_exp_root = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "# lr_exp_vowel = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "# lr_exp_consonant = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "learning_rate_reduction_root = ReduceLROnPlateau(monitor='dense_3_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "learning_rate_reduction_vowel = ReduceLROnPlateau(monitor='dense_4_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "learning_rate_reduction_consonant = ReduceLROnPlateau(monitor='dense_5_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(activation, dropout_prob):\n",
    "    inputs = Input(shape = (IMG_X_SIZE, IMG_Y_SIZE, N_CHANNELS))\n",
    "    # first convolutional layer\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation, input_shape=(IMG_X_SIZE, IMG_Y_SIZE, N_CHANNELS))(inputs)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 2nd CL\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 3rd CL\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 4th CL\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # dense layer\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(1024, activation=activation)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    dense = Dense(512, activation=activation)(model)\n",
    "    # softmax layer\n",
    "    head_root = Dense(168, activation = 'softmax', name = \"dense_root\")(dense)\n",
    "    head_vowel = Dense(11, activation = 'softmax', name = \"dense_vowel\")(dense)\n",
    "    head_consonant = Dense(7, activation = 'softmax', name = \"dense_consonant\")(dense)\n",
    "    # output\n",
    "    model = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = [\"tanh\", \"relu\"]\n",
    "dropout_probs = [0.2, 0.4]\n",
    "optimizers = ['adam', 'nadam']\n",
    "# lr_schedulers = ['exp', 'power']\n",
    "batch_sizes = [256,128]\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Training model_8:\n",
      "\t Activation: relu\n",
      "\t Dropout Probability: 0.2\n",
      "\t Optimizer: adam\n",
      "\t Batch Size: 256\n",
      "Epoch 1/10\n",
      "549/549 [==============================] - 239s 435ms/step - loss: 6.3028 - dense_root_loss: 4.2207 - dense_vowel_loss: 1.1938 - dense_consonant_loss: 0.8883 - dense_root_accuracy: 0.0740 - dense_vowel_accuracy: 0.5936 - dense_consonant_accuracy: 0.6979 - val_loss: 3.5593 - val_dense_root_loss: 2.7114 - val_dense_vowel_loss: 0.4464 - val_dense_consonant_loss: 0.4012 - val_dense_root_accuracy: 0.2635 - val_dense_vowel_accuracy: 0.8496 - val_dense_consonant_accuracy: 0.8629\n",
      "Epoch 2/10\n",
      "  1/549 [..............................] - ETA: 48s - loss: 3.9388 - dense_root_loss: 2.9029 - dense_vowel_loss: 0.6232 - dense_consonant_loss: 0.4128 - dense_root_accuracy: 0.2045 - dense_vowel_accuracy: 0.8182 - dense_consonant_accuracy: 0.8636"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_3_accuracy` which is not available. Available metrics are: dense_root_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_loss,dense_consonant_accuracy,dense_vowel_accuracy,val_dense_root_accuracy,loss,lr,dense_vowel_loss,val_dense_consonant_loss,val_dense_root_loss,val_loss,val_dense_consonant_accuracy,val_dense_vowel_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_4_accuracy` which is not available. Available metrics are: dense_root_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_loss,dense_consonant_accuracy,dense_vowel_accuracy,val_dense_root_accuracy,loss,lr,dense_vowel_loss,val_dense_consonant_loss,val_dense_root_loss,val_loss,val_dense_consonant_accuracy,val_dense_vowel_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_5_accuracy` which is not available. Available metrics are: dense_root_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_loss,dense_consonant_accuracy,dense_vowel_accuracy,val_dense_root_accuracy,loss,lr,dense_vowel_loss,val_dense_consonant_loss,val_dense_root_loss,val_loss,val_dense_consonant_accuracy,val_dense_vowel_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 230s 419ms/step - loss: 3.0191 - dense_root_loss: 2.0293 - dense_vowel_loss: 0.5754 - dense_consonant_loss: 0.4145 - dense_root_accuracy: 0.4412 - dense_vowel_accuracy: 0.8124 - dense_consonant_accuracy: 0.8631 - val_loss: 1.3248 - val_dense_root_loss: 0.9098 - val_dense_vowel_loss: 0.2253 - val_dense_consonant_loss: 0.1895 - val_dense_root_accuracy: 0.7309 - val_dense_vowel_accuracy: 0.9287 - val_dense_consonant_accuracy: 0.9399\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 1.7405 - dense_root_loss: 1.0757 - dense_vowel_loss: 0.3892 - dense_consonant_loss: 0.2755 - dense_root_accuracy: 0.6951 - dense_vowel_accuracy: 0.8793 - dense_consonant_accuracy: 0.9113 - val_loss: 0.8914 - val_dense_root_loss: 0.5795 - val_dense_vowel_loss: 0.1661 - val_dense_consonant_loss: 0.1454 - val_dense_root_accuracy: 0.8357 - val_dense_vowel_accuracy: 0.9525 - val_dense_consonant_accuracy: 0.9548\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 1.3070 - dense_root_loss: 0.7772 - dense_vowel_loss: 0.3110 - dense_consonant_loss: 0.2188 - dense_root_accuracy: 0.7815 - dense_vowel_accuracy: 0.9061 - dense_consonant_accuracy: 0.9303 - val_loss: 0.6885 - val_dense_root_loss: 0.4466 - val_dense_vowel_loss: 0.1307 - val_dense_consonant_loss: 0.1110 - val_dense_root_accuracy: 0.8750 - val_dense_vowel_accuracy: 0.9647 - val_dense_consonant_accuracy: 0.9664\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 1.1219 - dense_root_loss: 0.6468 - dense_vowel_loss: 0.2792 - dense_consonant_loss: 0.1959 - dense_root_accuracy: 0.8174 - dense_vowel_accuracy: 0.9171 - dense_consonant_accuracy: 0.9383 - val_loss: 0.6234 - val_dense_root_loss: 0.3937 - val_dense_vowel_loss: 0.1261 - val_dense_consonant_loss: 0.1032 - val_dense_root_accuracy: 0.8909 - val_dense_vowel_accuracy: 0.9655 - val_dense_consonant_accuracy: 0.9687\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 0.9997 - dense_root_loss: 0.5703 - dense_vowel_loss: 0.2527 - dense_consonant_loss: 0.1767 - dense_root_accuracy: 0.8406 - dense_vowel_accuracy: 0.9250 - dense_consonant_accuracy: 0.9447 - val_loss: 0.5541 - val_dense_root_loss: 0.3513 - val_dense_vowel_loss: 0.1083 - val_dense_consonant_loss: 0.0943 - val_dense_root_accuracy: 0.9008 - val_dense_vowel_accuracy: 0.9724 - val_dense_consonant_accuracy: 0.9722\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 0.9136 - dense_root_loss: 0.5161 - dense_vowel_loss: 0.2321 - dense_consonant_loss: 0.1654 - dense_root_accuracy: 0.8541 - dense_vowel_accuracy: 0.9316 - dense_consonant_accuracy: 0.9486 - val_loss: 0.5635 - val_dense_root_loss: 0.3544 - val_dense_vowel_loss: 0.1068 - val_dense_consonant_loss: 0.1021 - val_dense_root_accuracy: 0.9023 - val_dense_vowel_accuracy: 0.9718 - val_dense_consonant_accuracy: 0.9683\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 0.8470 - dense_root_loss: 0.4717 - dense_vowel_loss: 0.2212 - dense_consonant_loss: 0.1541 - dense_root_accuracy: 0.8656 - dense_vowel_accuracy: 0.9347 - dense_consonant_accuracy: 0.9522 - val_loss: 0.5042 - val_dense_root_loss: 0.3225 - val_dense_vowel_loss: 0.0991 - val_dense_consonant_loss: 0.0826 - val_dense_root_accuracy: 0.9106 - val_dense_vowel_accuracy: 0.9744 - val_dense_consonant_accuracy: 0.9753\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 0.7983 - dense_root_loss: 0.4459 - dense_vowel_loss: 0.2062 - dense_consonant_loss: 0.1463 - dense_root_accuracy: 0.8735 - dense_vowel_accuracy: 0.9398 - dense_consonant_accuracy: 0.9546 - val_loss: 0.4812 - val_dense_root_loss: 0.2938 - val_dense_vowel_loss: 0.1052 - val_dense_consonant_loss: 0.0822 - val_dense_root_accuracy: 0.9205 - val_dense_vowel_accuracy: 0.9719 - val_dense_consonant_accuracy: 0.9763\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 0.7595 - dense_root_loss: 0.4170 - dense_vowel_loss: 0.2007 - dense_consonant_loss: 0.1419 - dense_root_accuracy: 0.8825 - dense_vowel_accuracy: 0.9411 - dense_consonant_accuracy: 0.9563 - val_loss: 0.4708 - val_dense_root_loss: 0.2931 - val_dense_vowel_loss: 0.0962 - val_dense_consonant_loss: 0.0814 - val_dense_root_accuracy: 0.9204 - val_dense_vowel_accuracy: 0.9755 - val_dense_consonant_accuracy: 0.9768\n",
      "==========================================================================================\n",
      "Training model_12:\n",
      "\t Activation: relu\n",
      "\t Dropout Probability: 0.4\n",
      "\t Optimizer: adam\n",
      "\t Batch Size: 256\n",
      "Epoch 1/10\n",
      "549/549 [==============================] - 239s 435ms/step - loss: 6.8548 - dense_root_loss: 4.5421 - dense_vowel_loss: 1.3173 - dense_consonant_loss: 0.9953 - dense_root_accuracy: 0.0385 - dense_vowel_accuracy: 0.5447 - dense_consonant_accuracy: 0.6733 - val_loss: 5.3097 - val_dense_root_loss: 3.9747 - val_dense_vowel_loss: 0.7008 - val_dense_consonant_loss: 0.6337 - val_dense_root_accuracy: 0.0754 - val_dense_vowel_accuracy: 0.7627 - val_dense_consonant_accuracy: 0.7837\n",
      "Epoch 2/10\n",
      "  1/549 [..............................] - ETA: 48s - loss: 5.7625 - dense_root_loss: 4.1924 - dense_vowel_loss: 0.9676 - dense_consonant_loss: 0.6025 - dense_root_accuracy: 0.0682 - dense_vowel_accuracy: 0.6591 - dense_consonant_accuracy: 0.8409"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_3_accuracy` which is not available. Available metrics are: dense_root_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_loss,dense_consonant_accuracy,dense_vowel_accuracy,val_dense_root_accuracy,loss,lr,dense_vowel_loss,val_dense_consonant_loss,val_dense_root_loss,val_loss,val_dense_consonant_accuracy,val_dense_vowel_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_4_accuracy` which is not available. Available metrics are: dense_root_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_loss,dense_consonant_accuracy,dense_vowel_accuracy,val_dense_root_accuracy,loss,lr,dense_vowel_loss,val_dense_consonant_loss,val_dense_root_loss,val_loss,val_dense_consonant_accuracy,val_dense_vowel_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_5_accuracy` which is not available. Available metrics are: dense_root_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_loss,dense_consonant_accuracy,dense_vowel_accuracy,val_dense_root_accuracy,loss,lr,dense_vowel_loss,val_dense_consonant_loss,val_dense_root_loss,val_loss,val_dense_consonant_accuracy,val_dense_vowel_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 231s 420ms/step - loss: 4.9951 - dense_root_loss: 3.6262 - dense_vowel_loss: 0.7732 - dense_consonant_loss: 0.5957 - dense_root_accuracy: 0.1209 - dense_vowel_accuracy: 0.7455 - dense_consonant_accuracy: 0.7976 - val_loss: 3.2427 - val_dense_root_loss: 2.5412 - val_dense_vowel_loss: 0.3783 - val_dense_consonant_loss: 0.3228 - val_dense_root_accuracy: 0.2736 - val_dense_vowel_accuracy: 0.8770 - val_dense_consonant_accuracy: 0.8933\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 3.1034 - dense_root_loss: 2.1490 - dense_vowel_loss: 0.5640 - dense_consonant_loss: 0.3905 - dense_root_accuracy: 0.3974 - dense_vowel_accuracy: 0.8220 - dense_consonant_accuracy: 0.8743 - val_loss: 1.5934 - val_dense_root_loss: 1.1329 - val_dense_vowel_loss: 0.2498 - val_dense_consonant_loss: 0.2104 - val_dense_root_accuracy: 0.6632 - val_dense_vowel_accuracy: 0.9275 - val_dense_consonant_accuracy: 0.9370\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 2.0432 - dense_root_loss: 1.3159 - dense_vowel_loss: 0.4268 - dense_consonant_loss: 0.3004 - dense_root_accuracy: 0.6256 - dense_vowel_accuracy: 0.8690 - dense_consonant_accuracy: 0.9050 - val_loss: 0.9428 - val_dense_root_loss: 0.6263 - val_dense_vowel_loss: 0.1709 - val_dense_consonant_loss: 0.1456 - val_dense_root_accuracy: 0.8159 - val_dense_vowel_accuracy: 0.9521 - val_dense_consonant_accuracy: 0.9561\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 1.5558 - dense_root_loss: 0.9544 - dense_vowel_loss: 0.3528 - dense_consonant_loss: 0.2486 - dense_root_accuracy: 0.7323 - dense_vowel_accuracy: 0.8934 - dense_consonant_accuracy: 0.9222 - val_loss: 0.7547 - val_dense_root_loss: 0.4973 - val_dense_vowel_loss: 0.1314 - val_dense_consonant_loss: 0.1257 - val_dense_root_accuracy: 0.8580 - val_dense_vowel_accuracy: 0.9644 - val_dense_consonant_accuracy: 0.9612\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 1.3093 - dense_root_loss: 0.7792 - dense_vowel_loss: 0.3114 - dense_consonant_loss: 0.2187 - dense_root_accuracy: 0.7826 - dense_vowel_accuracy: 0.9080 - dense_consonant_accuracy: 0.9323 - val_loss: 0.6222 - val_dense_root_loss: 0.3988 - val_dense_vowel_loss: 0.1152 - val_dense_consonant_loss: 0.1080 - val_dense_root_accuracy: 0.8873 - val_dense_vowel_accuracy: 0.9687 - val_dense_consonant_accuracy: 0.9682\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 1.1523 - dense_root_loss: 0.6722 - dense_vowel_loss: 0.2818 - dense_consonant_loss: 0.1982 - dense_root_accuracy: 0.8120 - dense_vowel_accuracy: 0.9171 - dense_consonant_accuracy: 0.9391 - val_loss: 0.5811 - val_dense_root_loss: 0.3671 - val_dense_vowel_loss: 0.1113 - val_dense_consonant_loss: 0.1026 - val_dense_root_accuracy: 0.8967 - val_dense_vowel_accuracy: 0.9714 - val_dense_consonant_accuracy: 0.9688\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 1.0466 - dense_root_loss: 0.6026 - dense_vowel_loss: 0.2608 - dense_consonant_loss: 0.1833 - dense_root_accuracy: 0.8307 - dense_vowel_accuracy: 0.9242 - dense_consonant_accuracy: 0.9441 - val_loss: 0.5580 - val_dense_root_loss: 0.3552 - val_dense_vowel_loss: 0.1029 - val_dense_consonant_loss: 0.0997 - val_dense_root_accuracy: 0.9021 - val_dense_vowel_accuracy: 0.9740 - val_dense_consonant_accuracy: 0.9708\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 0.9697 - dense_root_loss: 0.5542 - dense_vowel_loss: 0.2427 - dense_consonant_loss: 0.1728 - dense_root_accuracy: 0.8460 - dense_vowel_accuracy: 0.9285 - dense_consonant_accuracy: 0.9472 - val_loss: 0.5310 - val_dense_root_loss: 0.3323 - val_dense_vowel_loss: 0.1030 - val_dense_consonant_loss: 0.0954 - val_dense_root_accuracy: 0.9083 - val_dense_vowel_accuracy: 0.9729 - val_dense_consonant_accuracy: 0.9731\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 0.9240 - dense_root_loss: 0.5202 - dense_vowel_loss: 0.2382 - dense_consonant_loss: 0.1655 - dense_root_accuracy: 0.8545 - dense_vowel_accuracy: 0.9311 - dense_consonant_accuracy: 0.9492 - val_loss: 0.4801 - val_dense_root_loss: 0.3000 - val_dense_vowel_loss: 0.0924 - val_dense_consonant_loss: 0.0876 - val_dense_root_accuracy: 0.9164 - val_dense_vowel_accuracy: 0.9759 - val_dense_consonant_accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "# TUNE THE MODEL\n",
    "if not os.path.exists(parent_directory+\"/models\"):\n",
    "    os.makedirs(parent_directory+\"/models\")\n",
    "histories = {}\n",
    "counter = 0 \n",
    "for activation in activations:\n",
    "    for dropout_prob in dropout_probs:\n",
    "        for optimizer in optimizers:\n",
    "            for batch_size in batch_sizes:\n",
    "    #             # MAKE SURE YOU EDIT THIS OUT LATER BUT THIS IS JUST TO SKIP MODEL 0 CUZ WE ALREADY TRIED IT\n",
    "                if not (counter==8 or counter==12):\n",
    "                    counter += 1\n",
    "                    continue\n",
    "                print(\"==========================================================================================\")\n",
    "                print(\"Training model_\"+str(counter) +\":\")\n",
    "                print(\"\\t Activation: \" + activation)\n",
    "                print(\"\\t Dropout Probability: \" + str(dropout_prob))\n",
    "                print(\"\\t Optimizer: \" + optimizer)\n",
    "                print(\"\\t Batch Size: \" + str(batch_size))\n",
    "                model = build_model(activation, dropout_prob)\n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                callbacks=[learning_rate_reduction_root, learning_rate_reduction_vowel, learning_rate_reduction_consonant]\n",
    "                history = model.fit_generator(\n",
    "                        datagen.flow(\n",
    "                            x_train, {'dense_root': y_train_root, 'dense_vowel': y_train_vowel, 'dense_consonant': y_train_consonant}, \n",
    "                            batch_size=batch_size),\n",
    "                        epochs = epochs, validation_data = (x_val, [y_val_root, y_val_vowel, y_val_consonant]), \n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size, \n",
    "                        callbacks=callbacks\n",
    "                    )\n",
    "                # need to change values of history to float64s or floats, float32 is not json serializable\n",
    "                for key in history.history.keys():\n",
    "                    history.history[key] = [np.float64(val) for val in history.history[key]]\n",
    "                # add history to histories\n",
    "                histories[\"model_\" + str(counter)] = (activation, dropout_prob, optimizer, batch_size, history.history)\n",
    "                # save histories as json file\n",
    "                with open(parent_directory+\"/models/model_\" + str(counter)+\".json\", \"w\") as fp:\n",
    "                    json.dump(history.history, fp, sort_keys = True, indent = 4)\n",
    "                counter += 1\n",
    "                del model\n",
    "                del history\n",
    "with open(parent_directory+\"/models/histories.json\", \"w\") as fp:\n",
    "    json.dump(histories, fp, sort_keys = True, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train\n",
    "del x_test\n",
    "del y_train_root\n",
    "del y_test_root\n",
    "del y_train_vowel\n",
    "del y_test_vowel\n",
    "del y_train_consonant\n",
    "del y_test_consonant\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg(vals):\n",
    "    return (vals['val_dense_root_accuracy'][-1]*2 + vals['val_dense_vowel_accuracy'][-1] + vals['val_dense_consonant_accuracy'][-1])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examining histories\n",
    "with open(parent_directory+\"/models/histories0-5.json\", \"r\") as fp:\n",
    "    history = json.load(fp)\n",
    "with open(parent_directory+\"/models/histories8&12.json\", \"r\") as fp:\n",
    "    history.update(json.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in history.keys():\n",
    "    # need to edit a mistake that listed \"exp\" learning rate, instead of the batch size\n",
    "    if int(key[-1])%2 == 0:\n",
    "        history[key][3] = 256\n",
    "    else:\n",
    "        history[key][3] = 128\n",
    "    history[key].append(history[key][4]['val_dense_root_accuracy'][-1])\n",
    "    history[key][4] = weighted_avg(history[key][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half way through we’re noticing that Adam isn’t performing well with these combinations. We also see that a lower dropout rate seems to give a better score on the validation set (not overfitting). This is why we stopped after model_5.\n",
    "\n",
    "We also see that batch size of 256 is performing better than batch size of 128. \n",
    "\n",
    "As a matter of time constraint we’ll remove nadam  and batch size = 128 and continue with the other options. Each model took around 40 minutes to run, at 10 epochs each. This lead to these results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>dropout_prob</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>weighted_avg_val_acc</th>\n",
       "      <th>val_root_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_0</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.20</td>\n",
       "      <td>adam</td>\n",
       "      <td>256</td>\n",
       "      <td>0.848636</td>\n",
       "      <td>0.762807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.20</td>\n",
       "      <td>adam</td>\n",
       "      <td>128</td>\n",
       "      <td>0.703620</td>\n",
       "      <td>0.528785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.20</td>\n",
       "      <td>nadam</td>\n",
       "      <td>256</td>\n",
       "      <td>0.198363</td>\n",
       "      <td>0.022320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.20</td>\n",
       "      <td>nadam</td>\n",
       "      <td>128</td>\n",
       "      <td>0.214879</td>\n",
       "      <td>0.017464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.40</td>\n",
       "      <td>adam</td>\n",
       "      <td>256</td>\n",
       "      <td>0.787214</td>\n",
       "      <td>0.660622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0.40</td>\n",
       "      <td>adam</td>\n",
       "      <td>128</td>\n",
       "      <td>0.625526</td>\n",
       "      <td>0.406238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_12</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.40</td>\n",
       "      <td>adam</td>\n",
       "      <td>256</td>\n",
       "      <td>0.945935</td>\n",
       "      <td>0.916369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_8</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.20</td>\n",
       "      <td>adam</td>\n",
       "      <td>256</td>\n",
       "      <td>0.948282</td>\n",
       "      <td>0.920407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_baseline</th>\n",
       "      <td>relu</td>\n",
       "      <td>0.33</td>\n",
       "      <td>adam</td>\n",
       "      <td>256</td>\n",
       "      <td>0.947350</td>\n",
       "      <td>0.919100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               activation  dropout_prob optimizer  batch_size  \\\n",
       "model_0              tanh          0.20      adam         256   \n",
       "model_1              tanh          0.20      adam         128   \n",
       "model_2              tanh          0.20     nadam         256   \n",
       "model_3              tanh          0.20     nadam         128   \n",
       "model_4              tanh          0.40      adam         256   \n",
       "model_5              tanh          0.40      adam         128   \n",
       "model_12             relu          0.40      adam         256   \n",
       "model_8              relu          0.20      adam         256   \n",
       "model_baseline       relu          0.33      adam         256   \n",
       "\n",
       "                weighted_avg_val_acc  val_root_acc  \n",
       "model_0                     0.848636      0.762807  \n",
       "model_1                     0.703620      0.528785  \n",
       "model_2                     0.198363      0.022320  \n",
       "model_3                     0.214879      0.017464  \n",
       "model_4                     0.787214      0.660622  \n",
       "model_5                     0.625526      0.406238  \n",
       "model_12                    0.945935      0.916369  \n",
       "model_8                     0.948282      0.920407  \n",
       "model_baseline              0.947350      0.919100  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the tuning results after 10 epochs\n",
    "cols = ['activation', 'dropout_prob', 'optimizer', 'batch_size','weighted_avg_val_acc', 'val_root_acc']\n",
    "tuning_results = pd.DataFrame.from_dict(history, orient='index', columns = cols)\n",
    "baseline_model = pd.DataFrame([['relu', 0.33, 'adam', 256, (0.9191*2 + 0.9759 +0.9753)/4, 0.9191]], columns = cols)\n",
    "baseline_model.rename(index={0:'model_baseline'}, inplace=True)\n",
    "tuning_results.append(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final results from this tuning is that we realized ReLU is a better activation function than tanh, it seems the lower dropout probability leads to a slight increase in the root accuracy, the adam optimizer looks a lot better than nadam, and a batch size of 256 is better than 128. \n",
    "\n",
    "Therefore, what we can explore next is a bigger range of dropout probabilities, and we can try to add more convolutional layers, we can try to add mc dropout, and run our final model for more epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
