{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "import time, gc\n",
    "import cv2\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import clone_model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = os.path.dirname(os.getcwd())\n",
    "\n",
    "def get_dummies(df):\n",
    "    cols = []\n",
    "    for col in df:\n",
    "        cols.append(pd.get_dummies(df[col].astype(str)))\n",
    "    return pd.concat(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_SIZE=64\n",
    "global IMG_X_SIZE\n",
    "IMG_X_SIZE = 87\n",
    "global IMG_Y_SIZE\n",
    "IMG_Y_SIZE = 106\n",
    "global N_CHANNELS\n",
    "N_CHANNELS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the preprocessed data for fitting in the model\n",
    "# this is for GCP or local\n",
    "proc_img_0 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_0.parquet\").to_pandas()\n",
    "proc_img_1 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_1.parquet\").to_pandas()\n",
    "proc_img_2 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_2.parquet\").to_pandas()\n",
    "proc_img_3 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_3.parquet\").to_pandas()\n",
    "train_images = pd.concat([proc_img_0, proc_img_1, proc_img_2, proc_img_3])\n",
    "train_images.drop(columns=['image_id'],inplace=True)\n",
    "del proc_img_0\n",
    "del proc_img_1\n",
    "del proc_img_2\n",
    "del proc_img_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN takes images in shape `(batch_size, h, w, channels)`, so reshape the images\n",
    "train_images = train_images.values.reshape(-1, IMG_X_SIZE, IMG_Y_SIZE, N_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(parent_directory+\"/data/train.csv\")\n",
    "Y_train_root = pd.get_dummies(train_labels['grapheme_root']).values\n",
    "Y_train_vowel = pd.get_dummies(train_labels['vowel_diacritic']).values\n",
    "Y_train_consonant = pd.get_dummies(train_labels['consonant_diacritic']).values\n",
    "del train_labels\n",
    "# print(f'Training images: {train_images.shape}')\n",
    "# print(f'Training labels root: {Y_train_root.shape}')\n",
    "# print(f'Training labels vowel: {Y_train_vowel.shape}')\n",
    "# print(f'Training labels consonants: {Y_train_consonant.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below this should take around 5 minutes\n",
    "x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant \\\n",
    "    = train_test_split(train_images, Y_train_root, Y_train_vowel, Y_train_consonant, test_size=0.3, random_state=666)\n",
    "del train_images\n",
    "x_val, x_test, y_val_root, y_test_root, y_val_vowel, y_test_vowel, y_val_consonant, y_test_consonant \\\n",
    "    = train_test_split(x_test, y_test_root, y_test_vowel, y_test_consonant, test_size=0.33, random_state=666)\n",
    "# print(f'x_train size: {x_train.shape}')\n",
    "# print(f'x_val size: {x_val.shape}')\n",
    "# print(f'x_test size: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n",
    "\n",
    "    def flow(self,\n",
    "             x,\n",
    "             y=None,\n",
    "             batch_size=32,\n",
    "             shuffle=True,\n",
    "             sample_weight=None,\n",
    "             seed=None,\n",
    "             save_to_dir=None,\n",
    "             save_prefix='',\n",
    "             save_format='png',\n",
    "             subset=None):\n",
    "\n",
    "        targets = None\n",
    "        target_lengths = {}\n",
    "        ordered_outputs = []\n",
    "        for output, target in y.items():\n",
    "            if targets is None:\n",
    "                targets = target\n",
    "            else:\n",
    "                targets = np.concatenate((targets, target), axis=1)\n",
    "            target_lengths[output] = target.shape[1]\n",
    "            ordered_outputs.append(output)\n",
    "\n",
    "\n",
    "        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n",
    "                                         shuffle=shuffle):\n",
    "            target_dict = {}\n",
    "            i = 0\n",
    "            for output in ordered_outputs:\n",
    "                target_length = target_lengths[output]\n",
    "                target_dict[output] = flowy[:, i: i + target_length]\n",
    "                i += target_length\n",
    "\n",
    "            yield flowx, target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data generator (should take two minutes)\n",
    "# Data augmentation for creating more training data\n",
    "datagen = MultiOutputDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.15, # Randomly zoom image \n",
    "    width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "# This will just calculate parameters required to augment the given data. This won't perform any augmentations\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Not going to use exponential anymore after realizing it sucks\n",
    "\"\"\"\n",
    "# need to edit these when we run the actual model and not doing hyperparameter tuning\n",
    "# initial_learning_rate = 0.01\n",
    "# decay_steps = 5 # this would be more like 10 or 20, since we'll be running more epochs\n",
    "# decay_rate = 0.1\n",
    "# learning_rate_exp_root = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#         initial_learning_rate = initial_learning_rate, decay_steps = decay_steps, decay_rate=decay_rate, name=\"lr_expD_root\")\n",
    "# learning_rate_exp_vowel = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#         initial_learning_rate = initial_learning_rate, decay_steps = decay_steps, decay_rate=decay_rate, name=\"lr_expD_vowel\")\n",
    "# learning_rate_exp_consonant = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#         initial_learning_rate = initial_learning_rate, decay_steps = decay_steps, decay_rate=decay_rate, name=\"lr_expD_consonant\")\n",
    "# LR_scheduler_exp_root = tf.keras.callbacks.LearningRateScheduler(learning_rate_exp_root)\n",
    "# LR_scheduler_exp_vowel = tf.keras.callbacks.LearningRateScheduler(learning_rate_exp_vowel)\n",
    "# LR_scheduler_exp_consonant = tf.keras.callbacks.LearningRateScheduler(learning_rate_exp_consonant)\n",
    "\n",
    "# def exponential_decay_fn(epoch):\n",
    "#     return 0.5 * 0.1 **(epoch / 3) # 1st var is initial lr, 2nd is decay_rate, 3rd is decay_steps, i think\n",
    "# lr_exp_root = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "# lr_exp_vowel = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "# lr_exp_consonant = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "learning_rate_reduction_root = ReduceLROnPlateau(monitor='dense_3_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "learning_rate_reduction_vowel = ReduceLROnPlateau(monitor='dense_4_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "learning_rate_reduction_consonant = ReduceLROnPlateau(monitor='dense_5_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(activation, dropout_prob):\n",
    "    inputs = Input(shape = (IMG_X_SIZE, IMG_Y_SIZE, N_CHANNELS))\n",
    "    # first convolutional layer\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation, input_shape=(IMG_X_SIZE, IMG_Y_SIZE, N_CHANNELS))(inputs)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 2nd CL\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 3rd CL\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 4th CL\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # dense layer\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(1024, activation=activation)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    dense = Dense(512, activation=activation)(model)\n",
    "    # softmax layer\n",
    "    head_root = Dense(168, activation = 'softmax', name = \"dense_root\")(dense)\n",
    "    head_vowel = Dense(11, activation = 'softmax', name = \"dense_vowel\")(dense)\n",
    "    head_consonant = Dense(7, activation = 'softmax', name = \"dense_consonant\")(dense)\n",
    "    # output\n",
    "    model = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = [\"tanh\", \"relu\"]\n",
    "dropout_probs = [0.2, 0.4]\n",
    "optimizers = ['adam', 'nadam']\n",
    "# lr_schedulers = ['exp', 'power']\n",
    "batch_sizes = [256,128]\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Training model_0:\n",
      "\t Activation: tanh\n",
      "\t Dropout Probability: 0.2\n",
      "\t Optimizer: adam\n",
      "\t Batch Size: 256\n",
      "Epoch 1/10\n",
      "549/549 [==============================] - 239s 436ms/step - loss: 6.1050 - dense_root_loss: 4.1703 - dense_vowel_loss: 1.1010 - dense_consonant_loss: 0.8337 - dense_root_accuracy: 0.0805 - dense_vowel_accuracy: 0.6243 - dense_consonant_accuracy: 0.7153 - val_loss: 3.9699 - val_dense_root_loss: 2.9886 - val_dense_vowel_loss: 0.5398 - val_dense_consonant_loss: 0.4412 - val_dense_root_accuracy: 0.2306 - val_dense_vowel_accuracy: 0.8263 - val_dense_consonant_accuracy: 0.8488\n",
      "Epoch 2/10\n",
      "  1/549 [..............................] - ETA: 47s - loss: 4.8142 - dense_root_loss: 3.3058 - dense_vowel_loss: 1.0545 - dense_consonant_loss: 0.4539 - dense_root_accuracy: 0.1818 - dense_vowel_accuracy: 0.6591 - dense_consonant_accuracy: 0.8636"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_3_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_4_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_5_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 231s 420ms/step - loss: 3.7480 - dense_root_loss: 2.5790 - dense_vowel_loss: 0.6648 - dense_consonant_loss: 0.5042 - dense_root_accuracy: 0.3249 - dense_vowel_accuracy: 0.7825 - dense_consonant_accuracy: 0.8310 - val_loss: 2.2805 - val_dense_root_loss: 1.6364 - val_dense_vowel_loss: 0.3479 - val_dense_consonant_loss: 0.2957 - val_dense_root_accuracy: 0.5352 - val_dense_vowel_accuracy: 0.8922 - val_dense_consonant_accuracy: 0.9051\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 2.7986 - dense_root_loss: 1.8360 - dense_vowel_loss: 0.5519 - dense_consonant_loss: 0.4107 - dense_root_accuracy: 0.4971 - dense_vowel_accuracy: 0.8223 - dense_consonant_accuracy: 0.8645 - val_loss: 1.7484 - val_dense_root_loss: 1.1970 - val_dense_vowel_loss: 0.3010 - val_dense_consonant_loss: 0.2501 - val_dense_root_accuracy: 0.6606 - val_dense_vowel_accuracy: 0.9073 - val_dense_consonant_accuracy: 0.9191\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 2.3832 - dense_root_loss: 1.5282 - dense_vowel_loss: 0.4855 - dense_consonant_loss: 0.3695 - dense_root_accuracy: 0.5794 - dense_vowel_accuracy: 0.8458 - dense_consonant_accuracy: 0.8793 - val_loss: 1.5080 - val_dense_root_loss: 1.0227 - val_dense_vowel_loss: 0.2552 - val_dense_consonant_loss: 0.2297 - val_dense_root_accuracy: 0.7138 - val_dense_vowel_accuracy: 0.9225 - val_dense_consonant_accuracy: 0.9246\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 2.2085 - dense_root_loss: 1.3983 - dense_vowel_loss: 0.4608 - dense_consonant_loss: 0.3494 - dense_root_accuracy: 0.6146 - dense_vowel_accuracy: 0.8535 - dense_consonant_accuracy: 0.8850 - val_loss: 1.4245 - val_dense_root_loss: 0.9662 - val_dense_vowel_loss: 0.2457 - val_dense_consonant_loss: 0.2124 - val_dense_root_accuracy: 0.7294 - val_dense_vowel_accuracy: 0.9261 - val_dense_consonant_accuracy: 0.9329\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 2.1141 - dense_root_loss: 1.3231 - dense_vowel_loss: 0.4490 - dense_consonant_loss: 0.3420 - dense_root_accuracy: 0.6340 - dense_vowel_accuracy: 0.8562 - dense_consonant_accuracy: 0.8889 - val_loss: 1.3458 - val_dense_root_loss: 0.9072 - val_dense_vowel_loss: 0.2250 - val_dense_consonant_loss: 0.2133 - val_dense_root_accuracy: 0.7430 - val_dense_vowel_accuracy: 0.9340 - val_dense_consonant_accuracy: 0.9312\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 2.0880 - dense_root_loss: 1.3043 - dense_vowel_loss: 0.4466 - dense_consonant_loss: 0.3372 - dense_root_accuracy: 0.6381 - dense_vowel_accuracy: 0.8574 - dense_consonant_accuracy: 0.8887 - val_loss: 1.3171 - val_dense_root_loss: 0.8881 - val_dense_vowel_loss: 0.2255 - val_dense_consonant_loss: 0.2033 - val_dense_root_accuracy: 0.7486 - val_dense_vowel_accuracy: 0.9332 - val_dense_consonant_accuracy: 0.9362\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 2.0451 - dense_root_loss: 1.2676 - dense_vowel_loss: 0.4435 - dense_consonant_loss: 0.3339 - dense_root_accuracy: 0.6489 - dense_vowel_accuracy: 0.8595 - dense_consonant_accuracy: 0.8907 - val_loss: 1.2955 - val_dense_root_loss: 0.8599 - val_dense_vowel_loss: 0.2294 - val_dense_consonant_loss: 0.2059 - val_dense_root_accuracy: 0.7601 - val_dense_vowel_accuracy: 0.9314 - val_dense_consonant_accuracy: 0.9355\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 2.0264 - dense_root_loss: 1.2556 - dense_vowel_loss: 0.4357 - dense_consonant_loss: 0.3351 - dense_root_accuracy: 0.6514 - dense_vowel_accuracy: 0.8621 - dense_consonant_accuracy: 0.8903 - val_loss: 1.3071 - val_dense_root_loss: 0.8690 - val_dense_vowel_loss: 0.2265 - val_dense_consonant_loss: 0.2113 - val_dense_root_accuracy: 0.7560 - val_dense_vowel_accuracy: 0.9322 - val_dense_consonant_accuracy: 0.9319\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 2.0451 - dense_root_loss: 1.2658 - dense_vowel_loss: 0.4456 - dense_consonant_loss: 0.3337 - dense_root_accuracy: 0.6504 - dense_vowel_accuracy: 0.8589 - dense_consonant_accuracy: 0.8911 - val_loss: 1.2596 - val_dense_root_loss: 0.8314 - val_dense_vowel_loss: 0.2253 - val_dense_consonant_loss: 0.2026 - val_dense_root_accuracy: 0.7628 - val_dense_vowel_accuracy: 0.9329 - val_dense_consonant_accuracy: 0.9360\n",
      "==========================================================================================\n",
      "Training model_1:\n",
      "\t Activation: tanh\n",
      "\t Dropout Probability: 0.2\n",
      "\t Optimizer: adam\n",
      "\t Batch Size: 128\n",
      "Epoch 1/10\n",
      "1098/1098 [==============================] - 257s 234ms/step - loss: 6.2988 - dense_root_loss: 4.2904 - dense_vowel_loss: 1.1602 - dense_consonant_loss: 0.8482 - dense_root_accuracy: 0.0681 - dense_vowel_accuracy: 0.6031 - dense_consonant_accuracy: 0.7091 - val_loss: 4.2889 - val_dense_root_loss: 3.2330 - val_dense_vowel_loss: 0.5678 - val_dense_consonant_loss: 0.4877 - val_dense_root_accuracy: 0.1889 - val_dense_vowel_accuracy: 0.8168 - val_dense_consonant_accuracy: 0.8364\n",
      "Epoch 2/10\n",
      "   1/1098 [..............................] - ETA: 1:37 - loss: 4.5336 - dense_root_loss: 3.3134 - dense_vowel_loss: 0.7476 - dense_consonant_loss: 0.4726 - dense_root_accuracy: 0.1818 - dense_vowel_accuracy: 0.7273 - dense_consonant_accuracy: 0.8409"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_3_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_4_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_5_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098/1098 [==============================] - 249s 227ms/step - loss: 4.4030 - dense_root_loss: 3.0460 - dense_vowel_loss: 0.7739 - dense_consonant_loss: 0.5830 - dense_root_accuracy: 0.2343 - dense_vowel_accuracy: 0.7432 - dense_consonant_accuracy: 0.8005 - val_loss: 3.1175 - val_dense_root_loss: 2.2735 - val_dense_vowel_loss: 0.4616 - val_dense_consonant_loss: 0.3825 - val_dense_root_accuracy: 0.3764 - val_dense_vowel_accuracy: 0.8525 - val_dense_consonant_accuracy: 0.8728\n",
      "Epoch 3/10\n",
      "1098/1098 [==============================] - 248s 226ms/step - loss: 3.6730 - dense_root_loss: 2.4684 - dense_vowel_loss: 0.6918 - dense_consonant_loss: 0.5128 - dense_root_accuracy: 0.3508 - dense_vowel_accuracy: 0.7723 - dense_consonant_accuracy: 0.8271 - val_loss: 2.4973 - val_dense_root_loss: 1.7731 - val_dense_vowel_loss: 0.3987 - val_dense_consonant_loss: 0.3259 - val_dense_root_accuracy: 0.5030 - val_dense_vowel_accuracy: 0.8752 - val_dense_consonant_accuracy: 0.8935\n",
      "Epoch 4/10\n",
      "1098/1098 [==============================] - 249s 227ms/step - loss: 3.3786 - dense_root_loss: 2.2348 - dense_vowel_loss: 0.6528 - dense_consonant_loss: 0.4910 - dense_root_accuracy: 0.4030 - dense_vowel_accuracy: 0.7866 - dense_consonant_accuracy: 0.8353 - val_loss: 2.3684 - val_dense_root_loss: 1.6441 - val_dense_vowel_loss: 0.3926 - val_dense_consonant_loss: 0.3312 - val_dense_root_accuracy: 0.5384 - val_dense_vowel_accuracy: 0.8745 - val_dense_consonant_accuracy: 0.8909\n",
      "Epoch 5/10\n",
      "1098/1098 [==============================] - 250s 227ms/step - loss: 3.2858 - dense_root_loss: 2.1466 - dense_vowel_loss: 0.6585 - dense_consonant_loss: 0.4807 - dense_root_accuracy: 0.4265 - dense_vowel_accuracy: 0.7829 - dense_consonant_accuracy: 0.8390 - val_loss: 2.3272 - val_dense_root_loss: 1.5945 - val_dense_vowel_loss: 0.3993 - val_dense_consonant_loss: 0.3341 - val_dense_root_accuracy: 0.5537 - val_dense_vowel_accuracy: 0.8760 - val_dense_consonant_accuracy: 0.8898\n",
      "Epoch 6/10\n",
      "1098/1098 [==============================] - 249s 226ms/step - loss: 3.2264 - dense_root_loss: 2.1039 - dense_vowel_loss: 0.6418 - dense_consonant_loss: 0.4807 - dense_root_accuracy: 0.4365 - dense_vowel_accuracy: 0.7898 - dense_consonant_accuracy: 0.8392 - val_loss: 2.3015 - val_dense_root_loss: 1.5929 - val_dense_vowel_loss: 0.3787 - val_dense_consonant_loss: 0.3306 - val_dense_root_accuracy: 0.5500 - val_dense_vowel_accuracy: 0.8780 - val_dense_consonant_accuracy: 0.8906\n",
      "Epoch 7/10\n",
      "1098/1098 [==============================] - 248s 226ms/step - loss: 3.2580 - dense_root_loss: 2.1143 - dense_vowel_loss: 0.6551 - dense_consonant_loss: 0.4886 - dense_root_accuracy: 0.4360 - dense_vowel_accuracy: 0.7835 - dense_consonant_accuracy: 0.8361 - val_loss: 2.3514 - val_dense_root_loss: 1.6512 - val_dense_vowel_loss: 0.3782 - val_dense_consonant_loss: 0.3227 - val_dense_root_accuracy: 0.5361 - val_dense_vowel_accuracy: 0.8796 - val_dense_consonant_accuracy: 0.8923\n",
      "Epoch 8/10\n",
      "1098/1098 [==============================] - 249s 226ms/step - loss: 3.2688 - dense_root_loss: 2.1217 - dense_vowel_loss: 0.6575 - dense_consonant_loss: 0.4896 - dense_root_accuracy: 0.4353 - dense_vowel_accuracy: 0.7843 - dense_consonant_accuracy: 0.8339 - val_loss: 2.2516 - val_dense_root_loss: 1.5545 - val_dense_vowel_loss: 0.3871 - val_dense_consonant_loss: 0.3100 - val_dense_root_accuracy: 0.5644 - val_dense_vowel_accuracy: 0.8806 - val_dense_consonant_accuracy: 0.8968\n",
      "Epoch 9/10\n",
      "1098/1098 [==============================] - 249s 227ms/step - loss: 3.3524 - dense_root_loss: 2.1725 - dense_vowel_loss: 0.6851 - dense_consonant_loss: 0.4948 - dense_root_accuracy: 0.4260 - dense_vowel_accuracy: 0.7734 - dense_consonant_accuracy: 0.8330 - val_loss: 2.2570 - val_dense_root_loss: 1.5642 - val_dense_vowel_loss: 0.3789 - val_dense_consonant_loss: 0.3146 - val_dense_root_accuracy: 0.5597 - val_dense_vowel_accuracy: 0.8842 - val_dense_consonant_accuracy: 0.8961\n",
      "Epoch 10/10\n",
      "1098/1098 [==============================] - 249s 227ms/step - loss: 3.3621 - dense_root_loss: 2.1773 - dense_vowel_loss: 0.6836 - dense_consonant_loss: 0.5012 - dense_root_accuracy: 0.4234 - dense_vowel_accuracy: 0.7733 - dense_consonant_accuracy: 0.8302 - val_loss: 2.4640 - val_dense_root_loss: 1.7017 - val_dense_vowel_loss: 0.4149 - val_dense_consonant_loss: 0.3479 - val_dense_root_accuracy: 0.5288 - val_dense_vowel_accuracy: 0.8715 - val_dense_consonant_accuracy: 0.8854\n",
      "==========================================================================================\n",
      "Training model_2:\n",
      "\t Activation: tanh\n",
      "\t Dropout Probability: 0.2\n",
      "\t Optimizer: nadam\n",
      "\t Batch Size: 256\n",
      "Epoch 1/10\n",
      "549/549 [==============================] - 242s 440ms/step - loss: 7.3595 - dense_root_loss: 4.6132 - dense_vowel_loss: 1.6369 - dense_consonant_loss: 1.1094 - dense_root_accuracy: 0.0369 - dense_vowel_accuracy: 0.4200 - dense_consonant_accuracy: 0.6386 - val_loss: 5.8543 - val_dense_root_loss: 4.1148 - val_dense_vowel_loss: 0.8979 - val_dense_consonant_loss: 0.8413 - val_dense_root_accuracy: 0.0772 - val_dense_vowel_accuracy: 0.6854 - val_dense_consonant_accuracy: 0.6871\n",
      "Epoch 2/10\n",
      "  1/549 [..............................] - ETA: 50s - loss: 6.0709 - dense_root_loss: 4.3346 - dense_vowel_loss: 0.8529 - dense_consonant_loss: 0.8834 - dense_root_accuracy: 0.0455 - dense_vowel_accuracy: 0.7273 - dense_consonant_accuracy: 0.7045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_3_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_4_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_5_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 233s 424ms/step - loss: 5.8492 - dense_root_loss: 3.9284 - dense_vowel_loss: 1.0972 - dense_consonant_loss: 0.8236 - dense_root_accuracy: 0.1036 - dense_vowel_accuracy: 0.6235 - dense_consonant_accuracy: 0.7120 - val_loss: 4.7395 - val_dense_root_loss: 3.3504 - val_dense_vowel_loss: 0.7300 - val_dense_consonant_loss: 0.6590 - val_dense_root_accuracy: 0.1687 - val_dense_vowel_accuracy: 0.7502 - val_dense_consonant_accuracy: 0.7624\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 233s 424ms/step - loss: 5.1212 - dense_root_loss: 3.4621 - dense_vowel_loss: 0.9345 - dense_consonant_loss: 0.7247 - dense_root_accuracy: 0.1664 - dense_vowel_accuracy: 0.6821 - dense_consonant_accuracy: 0.7447 - val_loss: 4.0960 - val_dense_root_loss: 2.9357 - val_dense_vowel_loss: 0.6153 - val_dense_consonant_loss: 0.5445 - val_dense_root_accuracy: 0.2462 - val_dense_vowel_accuracy: 0.7966 - val_dense_consonant_accuracy: 0.8071\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 233s 424ms/step - loss: 8.2622 - dense_root_loss: 4.8147 - dense_vowel_loss: 2.1920 - dense_consonant_loss: 1.2555 - dense_root_accuracy: 0.0254 - dense_vowel_accuracy: 0.1955 - dense_consonant_accuracy: 0.6217 - val_loss: 8.1978 - val_dense_root_loss: 4.8129 - val_dense_vowel_loss: 2.1719 - val_dense_consonant_loss: 1.2128 - val_dense_root_accuracy: 0.0272 - val_dense_vowel_accuracy: 0.2045 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 233s 424ms/step - loss: 8.1965 - dense_root_loss: 4.8128 - dense_vowel_loss: 2.1642 - dense_consonant_loss: 1.2195 - dense_root_accuracy: 0.0233 - dense_vowel_accuracy: 0.1904 - dense_consonant_accuracy: 0.6246 - val_loss: 8.1336 - val_dense_root_loss: 4.7663 - val_dense_vowel_loss: 2.1498 - val_dense_consonant_loss: 1.2173 - val_dense_root_accuracy: 0.0279 - val_dense_vowel_accuracy: 0.1839 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 233s 425ms/step - loss: 8.1789 - dense_root_loss: 4.8040 - dense_vowel_loss: 2.1591 - dense_consonant_loss: 1.2157 - dense_root_accuracy: 0.0240 - dense_vowel_accuracy: 0.1922 - dense_consonant_accuracy: 0.6251 - val_loss: 8.1306 - val_dense_root_loss: 4.7574 - val_dense_vowel_loss: 2.1493 - val_dense_consonant_loss: 1.2238 - val_dense_root_accuracy: 0.0251 - val_dense_vowel_accuracy: 0.2045 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 233s 424ms/step - loss: 8.1772 - dense_root_loss: 4.8032 - dense_vowel_loss: 2.1595 - dense_consonant_loss: 1.2145 - dense_root_accuracy: 0.0239 - dense_vowel_accuracy: 0.1912 - dense_consonant_accuracy: 0.6251 - val_loss: 8.1798 - val_dense_root_loss: 4.7743 - val_dense_vowel_loss: 2.1726 - val_dense_consonant_loss: 1.2327 - val_dense_root_accuracy: 0.0223 - val_dense_vowel_accuracy: 0.1839 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 233s 424ms/step - loss: 8.1637 - dense_root_loss: 4.7936 - dense_vowel_loss: 2.1557 - dense_consonant_loss: 1.2145 - dense_root_accuracy: 0.0243 - dense_vowel_accuracy: 0.1925 - dense_consonant_accuracy: 0.6249 - val_loss: 8.2197 - val_dense_root_loss: 4.7889 - val_dense_vowel_loss: 2.1998 - val_dense_consonant_loss: 1.2309 - val_dense_root_accuracy: 0.0272 - val_dense_vowel_accuracy: 0.1839 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 233s 424ms/step - loss: 8.1621 - dense_root_loss: 4.7955 - dense_vowel_loss: 2.1536 - dense_consonant_loss: 1.2130 - dense_root_accuracy: 0.0248 - dense_vowel_accuracy: 0.1931 - dense_consonant_accuracy: 0.6245 - val_loss: 8.1842 - val_dense_root_loss: 4.8065 - val_dense_vowel_loss: 2.1643 - val_dense_consonant_loss: 1.2132 - val_dense_root_accuracy: 0.0175 - val_dense_vowel_accuracy: 0.1839 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 233s 424ms/step - loss: 8.1542 - dense_root_loss: 4.7915 - dense_vowel_loss: 2.1532 - dense_consonant_loss: 1.2095 - dense_root_accuracy: 0.0247 - dense_vowel_accuracy: 0.1931 - dense_consonant_accuracy: 0.6253 - val_loss: 8.1586 - val_dense_root_loss: 4.7722 - val_dense_vowel_loss: 2.1756 - val_dense_consonant_loss: 1.2108 - val_dense_root_accuracy: 0.0223 - val_dense_vowel_accuracy: 0.1287 - val_dense_consonant_accuracy: 0.6201\n",
      "==========================================================================================\n",
      "Training model_3:\n",
      "\t Activation: tanh\n",
      "\t Dropout Probability: 0.2\n",
      "\t Optimizer: nadam\n",
      "\t Batch Size: 128\n",
      "Epoch 1/10\n",
      "1098/1098 [==============================] - 263s 239ms/step - loss: 7.2177 - dense_root_loss: 4.6063 - dense_vowel_loss: 1.5273 - dense_consonant_loss: 1.0841 - dense_root_accuracy: 0.0386 - dense_vowel_accuracy: 0.4584 - dense_consonant_accuracy: 0.6369 - val_loss: 6.0465 - val_dense_root_loss: 4.1622 - val_dense_vowel_loss: 0.9850 - val_dense_consonant_loss: 0.8996 - val_dense_root_accuracy: 0.0698 - val_dense_vowel_accuracy: 0.6567 - val_dense_consonant_accuracy: 0.6815\n",
      "Epoch 2/10\n",
      "   1/1098 [..............................] - ETA: 1:40 - loss: 6.7398 - dense_root_loss: 4.1819 - dense_vowel_loss: 1.4110 - dense_consonant_loss: 1.1469 - dense_root_accuracy: 0.1136 - dense_vowel_accuracy: 0.4773 - dense_consonant_accuracy: 0.5682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_3_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_4_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_5_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098/1098 [==============================] - 255s 232ms/step - loss: 6.4731 - dense_root_loss: 4.2310 - dense_vowel_loss: 1.2918 - dense_consonant_loss: 0.9504 - dense_root_accuracy: 0.0731 - dense_vowel_accuracy: 0.5459 - dense_consonant_accuracy: 0.6690 - val_loss: 5.8066 - val_dense_root_loss: 3.9813 - val_dense_vowel_loss: 0.9886 - val_dense_consonant_loss: 0.8367 - val_dense_root_accuracy: 0.0829 - val_dense_vowel_accuracy: 0.6461 - val_dense_consonant_accuracy: 0.7006\n",
      "Epoch 3/10\n",
      "1098/1098 [==============================] - 254s 231ms/step - loss: 7.6992 - dense_root_loss: 4.6495 - dense_vowel_loss: 1.9066 - dense_consonant_loss: 1.1432 - dense_root_accuracy: 0.0402 - dense_vowel_accuracy: 0.3010 - dense_consonant_accuracy: 0.6400 - val_loss: 8.2560 - val_dense_root_loss: 4.8518 - val_dense_vowel_loss: 2.1880 - val_dense_consonant_loss: 1.2156 - val_dense_root_accuracy: 0.0272 - val_dense_vowel_accuracy: 0.2045 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 4/10\n",
      "1098/1098 [==============================] - 254s 232ms/step - loss: 8.2350 - dense_root_loss: 4.8481 - dense_vowel_loss: 2.1673 - dense_consonant_loss: 1.2196 - dense_root_accuracy: 0.0226 - dense_vowel_accuracy: 0.1884 - dense_consonant_accuracy: 0.6249 - val_loss: 8.1982 - val_dense_root_loss: 4.8129 - val_dense_vowel_loss: 2.1685 - val_dense_consonant_loss: 1.2165 - val_dense_root_accuracy: 0.0251 - val_dense_vowel_accuracy: 0.1839 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 5/10\n",
      "1098/1098 [==============================] - 255s 232ms/step - loss: 8.2221 - dense_root_loss: 4.8427 - dense_vowel_loss: 2.1621 - dense_consonant_loss: 1.2173 - dense_root_accuracy: 0.0242 - dense_vowel_accuracy: 0.1889 - dense_consonant_accuracy: 0.6249 - val_loss: 8.2062 - val_dense_root_loss: 4.8135 - val_dense_vowel_loss: 2.1721 - val_dense_consonant_loss: 1.2202 - val_dense_root_accuracy: 0.0221 - val_dense_vowel_accuracy: 0.1839 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 6/10\n",
      "1098/1098 [==============================] - 254s 232ms/step - loss: 8.2119 - dense_root_loss: 4.8378 - dense_vowel_loss: 2.1592 - dense_consonant_loss: 1.2149 - dense_root_accuracy: 0.0229 - dense_vowel_accuracy: 0.1896 - dense_consonant_accuracy: 0.6250 - val_loss: 8.1920 - val_dense_root_loss: 4.8396 - val_dense_vowel_loss: 2.1470 - val_dense_consonant_loss: 1.2052 - val_dense_root_accuracy: 0.0221 - val_dense_vowel_accuracy: 0.2045 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 7/10\n",
      "1098/1098 [==============================] - 254s 231ms/step - loss: 8.2054 - dense_root_loss: 4.8360 - dense_vowel_loss: 2.1562 - dense_consonant_loss: 1.2132 - dense_root_accuracy: 0.0235 - dense_vowel_accuracy: 0.1934 - dense_consonant_accuracy: 0.6249 - val_loss: 8.1850 - val_dense_root_loss: 4.7990 - val_dense_vowel_loss: 2.1645 - val_dense_consonant_loss: 1.2212 - val_dense_root_accuracy: 0.0251 - val_dense_vowel_accuracy: 0.2045 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 8/10\n",
      "1098/1098 [==============================] - 254s 231ms/step - loss: 8.2041 - dense_root_loss: 4.8369 - dense_vowel_loss: 2.1554 - dense_consonant_loss: 1.2117 - dense_root_accuracy: 0.0239 - dense_vowel_accuracy: 0.1925 - dense_consonant_accuracy: 0.6251 - val_loss: 8.2287 - val_dense_root_loss: 4.8355 - val_dense_vowel_loss: 2.1729 - val_dense_consonant_loss: 1.2200 - val_dense_root_accuracy: 0.0299 - val_dense_vowel_accuracy: 0.1839 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 9/10\n",
      "1098/1098 [==============================] - 254s 231ms/step - loss: 8.2031 - dense_root_loss: 4.8367 - dense_vowel_loss: 2.1548 - dense_consonant_loss: 1.2116 - dense_root_accuracy: 0.0246 - dense_vowel_accuracy: 0.1927 - dense_consonant_accuracy: 0.6249 - val_loss: 8.2138 - val_dense_root_loss: 4.7936 - val_dense_vowel_loss: 2.1798 - val_dense_consonant_loss: 1.2402 - val_dense_root_accuracy: 0.0272 - val_dense_vowel_accuracy: 0.1839 - val_dense_consonant_accuracy: 0.6201\n",
      "Epoch 10/10\n",
      "1098/1098 [==============================] - 255s 232ms/step - loss: 8.2022 - dense_root_loss: 4.8378 - dense_vowel_loss: 2.1536 - dense_consonant_loss: 1.2109 - dense_root_accuracy: 0.0241 - dense_vowel_accuracy: 0.1937 - dense_consonant_accuracy: 0.6252 - val_loss: 8.2143 - val_dense_root_loss: 4.8256 - val_dense_vowel_loss: 2.1774 - val_dense_consonant_loss: 1.2109 - val_dense_root_accuracy: 0.0175 - val_dense_vowel_accuracy: 0.2045 - val_dense_consonant_accuracy: 0.6201\n",
      "==========================================================================================\n",
      "Training model_4:\n",
      "\t Activation: tanh\n",
      "\t Dropout Probability: 0.4\n",
      "\t Optimizer: adam\n",
      "\t Batch Size: 256\n",
      "Epoch 1/10\n",
      "549/549 [==============================] - 239s 435ms/step - loss: 6.9177 - dense_root_loss: 4.5717 - dense_vowel_loss: 1.3656 - dense_consonant_loss: 0.9804 - dense_root_accuracy: 0.0408 - dense_vowel_accuracy: 0.5245 - dense_consonant_accuracy: 0.6692 - val_loss: 5.0785 - val_dense_root_loss: 3.9249 - val_dense_vowel_loss: 0.5755 - val_dense_consonant_loss: 0.5776 - val_dense_root_accuracy: 0.0952 - val_dense_vowel_accuracy: 0.8102 - val_dense_consonant_accuracy: 0.7801\n",
      "Epoch 2/10\n",
      "  1/549 [..............................] - ETA: 47s - loss: 5.9557 - dense_root_loss: 4.2495 - dense_vowel_loss: 0.7552 - dense_consonant_loss: 0.9510 - dense_root_accuracy: 0.0682 - dense_vowel_accuracy: 0.7273 - dense_consonant_accuracy: 0.6818"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_3_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_4_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_5_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 230s 419ms/step - loss: 5.0123 - dense_root_loss: 3.5587 - dense_vowel_loss: 0.8097 - dense_consonant_loss: 0.6440 - dense_root_accuracy: 0.1476 - dense_vowel_accuracy: 0.7335 - dense_consonant_accuracy: 0.7750 - val_loss: 3.3819 - val_dense_root_loss: 2.5473 - val_dense_vowel_loss: 0.4410 - val_dense_consonant_loss: 0.3930 - val_dense_root_accuracy: 0.3152 - val_dense_vowel_accuracy: 0.8631 - val_dense_consonant_accuracy: 0.8654\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 3.9205 - dense_root_loss: 2.6961 - dense_vowel_loss: 0.6910 - dense_consonant_loss: 0.5335 - dense_root_accuracy: 0.2953 - dense_vowel_accuracy: 0.7753 - dense_consonant_accuracy: 0.8200 - val_loss: 2.5897 - val_dense_root_loss: 1.8804 - val_dense_vowel_loss: 0.3769 - val_dense_consonant_loss: 0.3321 - val_dense_root_accuracy: 0.4703 - val_dense_vowel_accuracy: 0.8825 - val_dense_consonant_accuracy: 0.8923\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 3.3831 - dense_root_loss: 2.2731 - dense_vowel_loss: 0.6279 - dense_consonant_loss: 0.4821 - dense_root_accuracy: 0.3892 - dense_vowel_accuracy: 0.7956 - dense_consonant_accuracy: 0.8384 - val_loss: 2.2023 - val_dense_root_loss: 1.5572 - val_dense_vowel_loss: 0.3397 - val_dense_consonant_loss: 0.3050 - val_dense_root_accuracy: 0.5592 - val_dense_vowel_accuracy: 0.8969 - val_dense_consonant_accuracy: 0.9006\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 3.1123 - dense_root_loss: 2.0582 - dense_vowel_loss: 0.5957 - dense_consonant_loss: 0.4584 - dense_root_accuracy: 0.4418 - dense_vowel_accuracy: 0.8075 - dense_consonant_accuracy: 0.8473 - val_loss: 2.0502 - val_dense_root_loss: 1.4330 - val_dense_vowel_loss: 0.3215 - val_dense_consonant_loss: 0.2954 - val_dense_root_accuracy: 0.5870 - val_dense_vowel_accuracy: 0.8980 - val_dense_consonant_accuracy: 0.9037\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 2.9984 - dense_root_loss: 1.9583 - dense_vowel_loss: 0.5916 - dense_consonant_loss: 0.4484 - dense_root_accuracy: 0.4674 - dense_vowel_accuracy: 0.8084 - dense_consonant_accuracy: 0.8508 - val_loss: 1.8989 - val_dense_root_loss: 1.3172 - val_dense_vowel_loss: 0.3129 - val_dense_consonant_loss: 0.2684 - val_dense_root_accuracy: 0.6215 - val_dense_vowel_accuracy: 0.9067 - val_dense_consonant_accuracy: 0.9120\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 2.8848 - dense_root_loss: 1.8673 - dense_vowel_loss: 0.5774 - dense_consonant_loss: 0.4400 - dense_root_accuracy: 0.4913 - dense_vowel_accuracy: 0.8117 - dense_consonant_accuracy: 0.8538 - val_loss: 1.7862 - val_dense_root_loss: 1.2277 - val_dense_vowel_loss: 0.2961 - val_dense_consonant_loss: 0.2620 - val_dense_root_accuracy: 0.6475 - val_dense_vowel_accuracy: 0.9102 - val_dense_consonant_accuracy: 0.9155\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 2.8209 - dense_root_loss: 1.8189 - dense_vowel_loss: 0.5715 - dense_consonant_loss: 0.4306 - dense_root_accuracy: 0.5037 - dense_vowel_accuracy: 0.8145 - dense_consonant_accuracy: 0.8569 - val_loss: 1.7642 - val_dense_root_loss: 1.2023 - val_dense_vowel_loss: 0.3036 - val_dense_consonant_loss: 0.2578 - val_dense_root_accuracy: 0.6613 - val_dense_vowel_accuracy: 0.9066 - val_dense_consonant_accuracy: 0.9155\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 2.7781 - dense_root_loss: 1.7821 - dense_vowel_loss: 0.5668 - dense_consonant_loss: 0.4291 - dense_root_accuracy: 0.5155 - dense_vowel_accuracy: 0.8163 - dense_consonant_accuracy: 0.8562 - val_loss: 1.7407 - val_dense_root_loss: 1.1853 - val_dense_vowel_loss: 0.2927 - val_dense_consonant_loss: 0.2624 - val_dense_root_accuracy: 0.6603 - val_dense_vowel_accuracy: 0.9124 - val_dense_consonant_accuracy: 0.9130\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 2.8004 - dense_root_loss: 1.7987 - dense_vowel_loss: 0.5691 - dense_consonant_loss: 0.4326 - dense_root_accuracy: 0.5098 - dense_vowel_accuracy: 0.8164 - dense_consonant_accuracy: 0.8561 - val_loss: 1.7423 - val_dense_root_loss: 1.1924 - val_dense_vowel_loss: 0.2913 - val_dense_consonant_loss: 0.2580 - val_dense_root_accuracy: 0.6606 - val_dense_vowel_accuracy: 0.9112 - val_dense_consonant_accuracy: 0.9164\n",
      "==========================================================================================\n",
      "Training model_5:\n",
      "\t Activation: tanh\n",
      "\t Dropout Probability: 0.4\n",
      "\t Optimizer: adam\n",
      "\t Batch Size: 128\n",
      "Epoch 1/10\n",
      "1098/1098 [==============================] - 258s 235ms/step - loss: 6.6065 - dense_root_loss: 4.4331 - dense_vowel_loss: 1.2486 - dense_consonant_loss: 0.9248 - dense_root_accuracy: 0.0520 - dense_vowel_accuracy: 0.5691 - dense_consonant_accuracy: 0.6832 - val_loss: 4.8046 - val_dense_root_loss: 3.6065 - val_dense_vowel_loss: 0.6123 - val_dense_consonant_loss: 0.5857 - val_dense_root_accuracy: 0.1281 - val_dense_vowel_accuracy: 0.7935 - val_dense_consonant_accuracy: 0.7860\n",
      "Epoch 2/10\n",
      "   1/1098 [..............................] - ETA: 1:37 - loss: 5.4792 - dense_root_loss: 3.6691 - dense_vowel_loss: 1.0472 - dense_consonant_loss: 0.7629 - dense_root_accuracy: 0.1136 - dense_vowel_accuracy: 0.6364 - dense_consonant_accuracy: 0.7273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_3_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_4_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_5_accuracy` which is not available. Available metrics are: val_dense_consonant_loss,val_dense_root_accuracy,dense_vowel_loss,val_dense_root_loss,lr,loss,val_dense_consonant_accuracy,dense_consonant_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_accuracy,val_loss,dense_vowel_accuracy,val_dense_vowel_loss,dense_root_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098/1098 [==============================] - 250s 227ms/step - loss: 5.0753 - dense_root_loss: 3.5344 - dense_vowel_loss: 0.8642 - dense_consonant_loss: 0.6768 - dense_root_accuracy: 0.1495 - dense_vowel_accuracy: 0.7084 - dense_consonant_accuracy: 0.7643 - val_loss: 3.6842 - val_dense_root_loss: 2.7246 - val_dense_vowel_loss: 0.5176 - val_dense_consonant_loss: 0.4418 - val_dense_root_accuracy: 0.2789 - val_dense_vowel_accuracy: 0.8319 - val_dense_consonant_accuracy: 0.8478\n",
      "Epoch 3/10\n",
      "1098/1098 [==============================] - 249s 227ms/step - loss: 4.4517 - dense_root_loss: 3.0454 - dense_vowel_loss: 0.7964 - dense_consonant_loss: 0.6100 - dense_root_accuracy: 0.2301 - dense_vowel_accuracy: 0.7367 - dense_consonant_accuracy: 0.7903 - val_loss: 3.1517 - val_dense_root_loss: 2.3117 - val_dense_vowel_loss: 0.4463 - val_dense_consonant_loss: 0.3933 - val_dense_root_accuracy: 0.3679 - val_dense_vowel_accuracy: 0.8573 - val_dense_consonant_accuracy: 0.8658\n",
      "Epoch 4/10\n",
      "1098/1098 [==============================] - 250s 227ms/step - loss: 4.2136 - dense_root_loss: 2.8344 - dense_vowel_loss: 0.7907 - dense_consonant_loss: 0.5885 - dense_root_accuracy: 0.2712 - dense_vowel_accuracy: 0.7380 - dense_consonant_accuracy: 0.7998 - val_loss: 3.0019 - val_dense_root_loss: 2.1591 - val_dense_vowel_loss: 0.4605 - val_dense_consonant_loss: 0.3827 - val_dense_root_accuracy: 0.4056 - val_dense_vowel_accuracy: 0.8495 - val_dense_consonant_accuracy: 0.8705\n",
      "Epoch 5/10\n",
      "1098/1098 [==============================] - 250s 227ms/step - loss: 4.0958 - dense_root_loss: 2.7436 - dense_vowel_loss: 0.7678 - dense_consonant_loss: 0.5844 - dense_root_accuracy: 0.2924 - dense_vowel_accuracy: 0.7457 - dense_consonant_accuracy: 0.8005 - val_loss: 3.0036 - val_dense_root_loss: 2.1445 - val_dense_vowel_loss: 0.4546 - val_dense_consonant_loss: 0.4047 - val_dense_root_accuracy: 0.4050 - val_dense_vowel_accuracy: 0.8592 - val_dense_consonant_accuracy: 0.8665\n",
      "Epoch 6/10\n",
      "1098/1098 [==============================] - 250s 227ms/step - loss: 4.0159 - dense_root_loss: 2.6741 - dense_vowel_loss: 0.7642 - dense_consonant_loss: 0.5776 - dense_root_accuracy: 0.3072 - dense_vowel_accuracy: 0.7467 - dense_consonant_accuracy: 0.8032 - val_loss: 2.8192 - val_dense_root_loss: 1.9956 - val_dense_vowel_loss: 0.4260 - val_dense_consonant_loss: 0.3978 - val_dense_root_accuracy: 0.4429 - val_dense_vowel_accuracy: 0.8651 - val_dense_consonant_accuracy: 0.8589\n",
      "Epoch 7/10\n",
      "1098/1098 [==============================] - 250s 227ms/step - loss: 3.9734 - dense_root_loss: 2.6322 - dense_vowel_loss: 0.7575 - dense_consonant_loss: 0.5837 - dense_root_accuracy: 0.3168 - dense_vowel_accuracy: 0.7473 - dense_consonant_accuracy: 0.8001 - val_loss: 2.7440 - val_dense_root_loss: 1.9242 - val_dense_vowel_loss: 0.4385 - val_dense_consonant_loss: 0.3812 - val_dense_root_accuracy: 0.4659 - val_dense_vowel_accuracy: 0.8624 - val_dense_consonant_accuracy: 0.8729\n",
      "Epoch 8/10\n",
      "1098/1098 [==============================] - 250s 228ms/step - loss: 4.0326 - dense_root_loss: 2.6527 - dense_vowel_loss: 0.7894 - dense_consonant_loss: 0.5904 - dense_root_accuracy: 0.3176 - dense_vowel_accuracy: 0.7380 - dense_consonant_accuracy: 0.7976 - val_loss: 2.9883 - val_dense_root_loss: 2.1064 - val_dense_vowel_loss: 0.4808 - val_dense_consonant_loss: 0.4012 - val_dense_root_accuracy: 0.4213 - val_dense_vowel_accuracy: 0.8475 - val_dense_consonant_accuracy: 0.8658\n",
      "Epoch 9/10\n",
      "1098/1098 [==============================] - 250s 228ms/step - loss: 4.1191 - dense_root_loss: 2.7060 - dense_vowel_loss: 0.8133 - dense_consonant_loss: 0.5997 - dense_root_accuracy: 0.3071 - dense_vowel_accuracy: 0.7286 - dense_consonant_accuracy: 0.7953 - val_loss: 2.9531 - val_dense_root_loss: 2.0679 - val_dense_vowel_loss: 0.4745 - val_dense_consonant_loss: 0.4115 - val_dense_root_accuracy: 0.4300 - val_dense_vowel_accuracy: 0.8495 - val_dense_consonant_accuracy: 0.8653\n",
      "Epoch 10/10\n",
      "1098/1098 [==============================] - 250s 228ms/step - loss: 4.1291 - dense_root_loss: 2.7089 - dense_vowel_loss: 0.8075 - dense_consonant_loss: 0.6127 - dense_root_accuracy: 0.3067 - dense_vowel_accuracy: 0.7293 - dense_consonant_accuracy: 0.7908 - val_loss: 3.1180 - val_dense_root_loss: 2.1851 - val_dense_vowel_loss: 0.4928 - val_dense_consonant_loss: 0.4401 - val_dense_root_accuracy: 0.4062 - val_dense_vowel_accuracy: 0.8404 - val_dense_consonant_accuracy: 0.8493\n",
      "==========================================================================================\n",
      "Training model_6:\n",
      "\t Activation: tanh\n",
      "\t Dropout Probability: 0.4\n",
      "\t Optimizer: nadam\n",
      "\t Batch Size: 256\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-6002f8808d34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_val_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_vowel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_consonant\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                     )\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# need to change values of history to float64s or floats, float32 is not json serializable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \"\"\"\n\u001b[0;32m--> 650\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-625a66867bbe>\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n\u001b[0;32m---> 28\u001b[0;31m                                          shuffle=shuffle):\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mtarget_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         )\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    110\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_misc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_misc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TUNE THE MODEL\n",
    "if not os.path.exists(parent_directory+\"/models\"):\n",
    "    os.makedirs(parent_directory+\"/models\")\n",
    "histories = {}\n",
    "counter = 0 \n",
    "for activation in activations:\n",
    "    for dropout_prob in dropout_probs:\n",
    "        for optimizer in optimizers:\n",
    "            for batch_size in batch_sizes:\n",
    "    #             # MAKE SURE YOU EDIT THIS OUT LATER BUT THIS IS JUST TO SKIP MODEL 0 CUZ WE ALREADY TRIED IT\n",
    "                if counter <= 5:\n",
    "                    counter += 1\n",
    "                    continue\n",
    "                print(\"==========================================================================================\")\n",
    "                print(\"Training model_\"+str(counter) +\":\")\n",
    "                print(\"\\t Activation: \" + activation)\n",
    "                print(\"\\t Dropout Probability: \" + str(dropout_prob))\n",
    "                print(\"\\t Optimizer: \" + optimizer)\n",
    "                print(\"\\t Batch Size: \" + str(batch_size))\n",
    "                model = build_model(activation, dropout_prob)\n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                callbacks=[learning_rate_reduction_root, learning_rate_reduction_vowel, learning_rate_reduction_consonant]\n",
    "                history = model.fit_generator(\n",
    "                        datagen.flow(\n",
    "                            x_train, {'dense_root': y_train_root, 'dense_vowel': y_train_vowel, 'dense_consonant': y_train_consonant}, \n",
    "                            batch_size=batch_size),\n",
    "                        epochs = epochs, validation_data = (x_val, [y_val_root, y_val_vowel, y_val_consonant]), \n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size, \n",
    "                        callbacks=callbacks\n",
    "                    )\n",
    "                # need to change values of history to float64s or floats, float32 is not json serializable\n",
    "                for key in history.history.keys():\n",
    "                    history.history[key] = [np.float64(val) for val in history.history[key]]\n",
    "                # add history to histories\n",
    "                histories[\"model_\" + str(counter)] = (activation, dropout_prob, optimizer, lr, history.history)\n",
    "                # save histories as json file\n",
    "                with open(parent_directory+\"/models/model_\" + str(counter)+\".json\", \"w\") as fp:\n",
    "                    json.dump(history.history, fp, sort_keys = True, indent = 4)\n",
    "                counter += 1\n",
    "                del model\n",
    "                del history\n",
    "with open(parent_directory+\"/models/histories.json\", \"w\") as fp:\n",
    "    json.dump(histories, fp, sort_keys = True, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(parent_directory+\"/models/histories.json\", \"w\") as fp:\n",
    "    json.dump(histories, fp, sort_keys = True, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_0': ('tanh',\n",
       "  0.2,\n",
       "  'adam',\n",
       "  'exp',\n",
       "  {'dense_consonant_accuracy': [0.7153489589691162,\n",
       "    0.830986499786377,\n",
       "    0.8645355105400085,\n",
       "    0.8792933821678162,\n",
       "    0.8850440382957458,\n",
       "    0.8889134526252747,\n",
       "    0.8886640071868896,\n",
       "    0.8907376527786255,\n",
       "    0.8902531266212463,\n",
       "    0.8910797238349915],\n",
       "   'dense_consonant_loss': [0.8337407112121582,\n",
       "    0.5041878819465637,\n",
       "    0.410670667886734,\n",
       "    0.3695290684700012,\n",
       "    0.34943297505378723,\n",
       "    0.34197208285331726,\n",
       "    0.337189257144928,\n",
       "    0.33394184708595276,\n",
       "    0.33507055044174194,\n",
       "    0.3337043225765228],\n",
       "   'dense_root_accuracy': [0.08045167475938797,\n",
       "    0.3248724341392517,\n",
       "    0.4970569908618927,\n",
       "    0.5793760418891907,\n",
       "    0.6145996451377869,\n",
       "    0.6340250372886658,\n",
       "    0.6380725502967834,\n",
       "    0.648861289024353,\n",
       "    0.6514408588409424,\n",
       "    0.6503862142562866],\n",
       "   'dense_root_loss': [4.170259475708008,\n",
       "    2.5790419578552246,\n",
       "    1.8359626531600952,\n",
       "    1.528229832649231,\n",
       "    1.39825439453125,\n",
       "    1.3231263160705566,\n",
       "    1.3042891025543213,\n",
       "    1.2676481008529663,\n",
       "    1.2556109428405762,\n",
       "    1.2657874822616577],\n",
       "   'dense_vowel_accuracy': [0.6243026852607727,\n",
       "    0.7825086116790771,\n",
       "    0.8223356008529663,\n",
       "    0.8457515239715576,\n",
       "    0.8535187840461731,\n",
       "    0.8561625480651855,\n",
       "    0.8574166893959045,\n",
       "    0.8594689965248108,\n",
       "    0.8620628118515015,\n",
       "    0.8589202761650085],\n",
       "   'dense_vowel_loss': [1.1010299921035767,\n",
       "    0.6647822856903076,\n",
       "    0.5519440174102783,\n",
       "    0.4854833483695984,\n",
       "    0.460762083530426,\n",
       "    0.4489850103855133,\n",
       "    0.4465622901916504,\n",
       "    0.4434627890586853,\n",
       "    0.43570005893707275,\n",
       "    0.4455600082874298],\n",
       "   'loss': [6.1050280465020075,\n",
       "    3.7464013426006817,\n",
       "    2.7972903465445187,\n",
       "    2.3811351258864213,\n",
       "    2.2088770202610024,\n",
       "    2.1144701957437597,\n",
       "    2.086568362553226,\n",
       "    2.0446365771222825,\n",
       "    2.0265459703161586,\n",
       "    2.044966940284098],\n",
       "   'lr': [0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513],\n",
       "   'val_dense_consonant_accuracy': [0.8487663269042969,\n",
       "    0.9051228761672974,\n",
       "    0.9190695881843567,\n",
       "    0.9246432781219482,\n",
       "    0.9329419136047363,\n",
       "    0.9312326312065125,\n",
       "    0.9362366199493408,\n",
       "    0.9355430006980896,\n",
       "    0.9318767189979553,\n",
       "    0.9359889030456543],\n",
       "   'val_dense_consonant_loss': [0.4412265121936798,\n",
       "    0.2957174777984619,\n",
       "    0.2500893771648407,\n",
       "    0.229720339179039,\n",
       "    0.21244363486766815,\n",
       "    0.21328191459178925,\n",
       "    0.20331868529319763,\n",
       "    0.20585395395755768,\n",
       "    0.21128956973552704,\n",
       "    0.20260491967201233],\n",
       "   'val_dense_root_accuracy': [0.23062822222709656,\n",
       "    0.5351516008377075,\n",
       "    0.6606222987174988,\n",
       "    0.7138079404830933,\n",
       "    0.7294144034385681,\n",
       "    0.7429647445678711,\n",
       "    0.7485632300376892,\n",
       "    0.7601070404052734,\n",
       "    0.7560443878173828,\n",
       "    0.7628071904182434],\n",
       "   'val_dense_root_loss': [2.9886224269866943,\n",
       "    1.636429786682129,\n",
       "    1.1969642639160156,\n",
       "    1.022706389427185,\n",
       "    0.9661627411842346,\n",
       "    0.9072456955909729,\n",
       "    0.8881219029426575,\n",
       "    0.8599123358726501,\n",
       "    0.8690063953399658,\n",
       "    0.8313584923744202],\n",
       "   'val_dense_vowel_accuracy': [0.8262980580329895,\n",
       "    0.8921918272972107,\n",
       "    0.9073275923728943,\n",
       "    0.9225128889083862,\n",
       "    0.9261048436164856,\n",
       "    0.9340319037437439,\n",
       "    0.9331896305084229,\n",
       "    0.9313812851905823,\n",
       "    0.932174026966095,\n",
       "    0.9329419136047363],\n",
       "   'val_dense_vowel_loss': [0.539808452129364,\n",
       "    0.347901314496994,\n",
       "    0.30104631185531616,\n",
       "    0.2552106976509094,\n",
       "    0.24572929739952087,\n",
       "    0.22504085302352905,\n",
       "    0.22552786767482758,\n",
       "    0.2293962687253952,\n",
       "    0.22647693753242493,\n",
       "    0.22533859312534332],\n",
       "   'val_loss': [3.9698780708449064,\n",
       "    2.2804799870843695,\n",
       "    1.748372361010802,\n",
       "    1.508048933789317,\n",
       "    1.4244906141603932,\n",
       "    1.345772949845083,\n",
       "    1.317107689319222,\n",
       "    1.2955239913409728,\n",
       "    1.3070747534811993,\n",
       "    1.2595766168523297]}),\n",
       " 'model_1': ('tanh',\n",
       "  0.2,\n",
       "  'adam',\n",
       "  'exp',\n",
       "  {'dense_consonant_accuracy': [0.7090804576873779,\n",
       "    0.8005339503288269,\n",
       "    0.8271109461784363,\n",
       "    0.8352840542793274,\n",
       "    0.8390360474586487,\n",
       "    0.8392425179481506,\n",
       "    0.8361384272575378,\n",
       "    0.8338673114776611,\n",
       "    0.8330414295196533,\n",
       "    0.8301580548286438],\n",
       "   'dense_consonant_loss': [0.8482224345207214,\n",
       "    0.5830042362213135,\n",
       "    0.5128202438354492,\n",
       "    0.49098557233810425,\n",
       "    0.48068520426750183,\n",
       "    0.4807240068912506,\n",
       "    0.488582581281662,\n",
       "    0.48957398533821106,\n",
       "    0.4948359727859497,\n",
       "    0.5011873245239258],\n",
       "   'dense_root_accuracy': [0.0680854395031929,\n",
       "    0.23428022861480713,\n",
       "    0.3507831394672394,\n",
       "    0.40301865339279175,\n",
       "    0.4265128970146179,\n",
       "    0.43646588921546936,\n",
       "    0.43598178029060364,\n",
       "    0.43525558710098267,\n",
       "    0.42600739002227783,\n",
       "    0.4234159290790558],\n",
       "   'dense_root_loss': [4.290377140045166,\n",
       "    3.0460422039031982,\n",
       "    2.4683563709259033,\n",
       "    2.2348110675811768,\n",
       "    2.146637439727783,\n",
       "    2.1038730144500732,\n",
       "    2.1143057346343994,\n",
       "    2.121692419052124,\n",
       "    2.172473669052124,\n",
       "    2.177278995513916],\n",
       "   'dense_vowel_accuracy': [0.6030922532081604,\n",
       "    0.7432436347007751,\n",
       "    0.7722696661949158,\n",
       "    0.7865584492683411,\n",
       "    0.782863438129425,\n",
       "    0.7898262739181519,\n",
       "    0.7835255861282349,\n",
       "    0.7842588424682617,\n",
       "    0.773358941078186,\n",
       "    0.7733305096626282],\n",
       "   'dense_vowel_loss': [1.1601922512054443,\n",
       "    0.7739391326904297,\n",
       "    0.6917765140533447,\n",
       "    0.6528014540672302,\n",
       "    0.6584819555282593,\n",
       "    0.6418158411979675,\n",
       "    0.6550992727279663,\n",
       "    0.657509446144104,\n",
       "    0.6851291060447693,\n",
       "    0.6836275458335876],\n",
       "   'loss': [6.298793591653932,\n",
       "    4.402907525225105,\n",
       "    3.6724705827010418,\n",
       "    3.3786626958242767,\n",
       "    3.2857214298272734,\n",
       "    3.226847185403486,\n",
       "    3.2577419744874785,\n",
       "    3.268934523018782,\n",
       "    3.3526267067991937,\n",
       "    3.3619518240513533],\n",
       "   'lr': [0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513],\n",
       "   'val_dense_consonant_accuracy': [0.8364298343658447,\n",
       "    0.8727704882621765,\n",
       "    0.8934552073478699,\n",
       "    0.8909037113189697,\n",
       "    0.8897889256477356,\n",
       "    0.8906311988830566,\n",
       "    0.892315685749054,\n",
       "    0.8968489766120911,\n",
       "    0.8961306214332581,\n",
       "    0.8854290246963501],\n",
       "   'val_dense_consonant_loss': [0.48772817850112915,\n",
       "    0.382463663816452,\n",
       "    0.32585570216178894,\n",
       "    0.3312280476093292,\n",
       "    0.33406737446784973,\n",
       "    0.3306327164173126,\n",
       "    0.3227328956127167,\n",
       "    0.3099788427352905,\n",
       "    0.31464046239852905,\n",
       "    0.3478999137878418],\n",
       "   'val_dense_root_accuracy': [0.18888723850250244,\n",
       "    0.3764120042324066,\n",
       "    0.5029973983764648,\n",
       "    0.5383719801902771,\n",
       "    0.5536563396453857,\n",
       "    0.5500396490097046,\n",
       "    0.5360929369926453,\n",
       "    0.5643826723098755,\n",
       "    0.5596759915351868,\n",
       "    0.5287851691246033],\n",
       "   'val_dense_root_loss': [3.2329599857330322,\n",
       "    2.273505210876465,\n",
       "    1.7730743885040283,\n",
       "    1.6441220045089722,\n",
       "    1.594468116760254,\n",
       "    1.5928789377212524,\n",
       "    1.6512198448181152,\n",
       "    1.5545397996902466,\n",
       "    1.564191460609436,\n",
       "    1.7017196416854858],\n",
       "   'val_dense_vowel_accuracy': [0.8168103694915771,\n",
       "    0.8525317311286926,\n",
       "    0.8751981854438782,\n",
       "    0.8745293021202087,\n",
       "    0.8759908676147461,\n",
       "    0.8779973983764648,\n",
       "    0.8796323537826538,\n",
       "    0.8806480169296265,\n",
       "    0.8841904401779175,\n",
       "    0.8714823722839355],\n",
       "   'val_dense_vowel_loss': [0.5677709579467773,\n",
       "    0.46157780289649963,\n",
       "    0.39868202805519104,\n",
       "    0.3925923705101013,\n",
       "    0.3993154764175415,\n",
       "    0.37874823808670044,\n",
       "    0.37821894884109497,\n",
       "    0.3871045708656311,\n",
       "    0.3788502514362335,\n",
       "    0.4149036109447479],\n",
       "   'val_loss': [4.28889195766895,\n",
       "    3.117487016765551,\n",
       "    2.4973107050488594,\n",
       "    2.368364382961937,\n",
       "    2.3272355882317313,\n",
       "    2.3015145193335087,\n",
       "    2.351386879154769,\n",
       "    2.251645072981615,\n",
       "    2.2570036171071357,\n",
       "    2.463969171023586]}),\n",
       " 'model_2': ('tanh',\n",
       "  0.2,\n",
       "  'nadam',\n",
       "  'exp',\n",
       "  {'dense_consonant_accuracy': [0.6386469602584839,\n",
       "    0.7119972705841064,\n",
       "    0.7446840405464172,\n",
       "    0.62168288230896,\n",
       "    0.624590277671814,\n",
       "    0.6251175999641418,\n",
       "    0.6251246929168701,\n",
       "    0.6249322891235352,\n",
       "    0.6245261430740356,\n",
       "    0.6252672076225281],\n",
       "   'dense_consonant_loss': [1.1093608140945435,\n",
       "    0.8235564827919006,\n",
       "    0.7246729731559753,\n",
       "    1.255475401878357,\n",
       "    1.219467282295227,\n",
       "    1.2157436609268188,\n",
       "    1.214453935623169,\n",
       "    1.2144733667373657,\n",
       "    1.2129855155944824,\n",
       "    1.2095307111740112],\n",
       "   'dense_root_accuracy': [0.0368923619389534,\n",
       "    0.1035686805844307,\n",
       "    0.16641250252723694,\n",
       "    0.025425419211387634,\n",
       "    0.023330388590693474,\n",
       "    0.024000227451324463,\n",
       "    0.02394322119653225,\n",
       "    0.02427813969552517,\n",
       "    0.02481258660554886,\n",
       "    0.024727076292037964],\n",
       "   'dense_root_loss': [4.613177299499512,\n",
       "    3.928417921066284,\n",
       "    3.462066173553467,\n",
       "    4.814720153808594,\n",
       "    4.812802314758301,\n",
       "    4.804044246673584,\n",
       "    4.803223609924316,\n",
       "    4.793560981750488,\n",
       "    4.795528888702393,\n",
       "    4.79146671295166],\n",
       "   'dense_vowel_accuracy': [0.42001792788505554,\n",
       "    0.6235356330871582,\n",
       "    0.6821109652519226,\n",
       "    0.19547216594219208,\n",
       "    0.1904127299785614,\n",
       "    0.1922227293252945,\n",
       "    0.19120371341705322,\n",
       "    0.19252201914787292,\n",
       "    0.19310635328292847,\n",
       "    0.19307072460651398],\n",
       "   'dense_vowel_loss': [1.6369445323944092,\n",
       "    1.0972322225570679,\n",
       "    0.934501051902771,\n",
       "    2.1920435428619385,\n",
       "    2.164186477661133,\n",
       "    2.159116268157959,\n",
       "    2.159508466720581,\n",
       "    2.1556646823883057,\n",
       "    2.153597116470337,\n",
       "    2.1531505584716797],\n",
       "   'loss': [7.359482928486252,\n",
       "    5.848872876502332,\n",
       "    5.120789958233063,\n",
       "    8.267190512836658,\n",
       "    8.196236965182814,\n",
       "    8.178773634647747,\n",
       "    8.17694649904167,\n",
       "    8.16385604170224,\n",
       "    8.162139196330362,\n",
       "    8.15414543098576],\n",
       "   'lr': [0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026],\n",
       "   'val_dense_consonant_accuracy': [0.6870788931846619,\n",
       "    0.7624108195304871,\n",
       "    0.8070749044418335,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149],\n",
       "   'val_dense_consonant_loss': [0.8412973880767822,\n",
       "    0.6589599847793579,\n",
       "    0.544544517993927,\n",
       "    1.212827444076538,\n",
       "    1.2173157930374146,\n",
       "    1.2238335609436035,\n",
       "    1.2326678037643433,\n",
       "    1.2308703660964966,\n",
       "    1.2132453918457031,\n",
       "    1.2108304500579834],\n",
       "   'val_dense_root_accuracy': [0.07721462845802307,\n",
       "    0.16874752938747406,\n",
       "    0.2461850941181183,\n",
       "    0.027174990624189377,\n",
       "    0.02786860801279545,\n",
       "    0.025069361552596092,\n",
       "    0.02231965959072113,\n",
       "    0.027174990624189377,\n",
       "    0.017464328557252884,\n",
       "    0.02231965959072113],\n",
       "   'val_dense_root_loss': [4.114812850952148,\n",
       "    3.3503711223602295,\n",
       "    2.9357240200042725,\n",
       "    4.812905311584473,\n",
       "    4.76628303527832,\n",
       "    4.757361888885498,\n",
       "    4.774273872375488,\n",
       "    4.788874626159668,\n",
       "    4.806513786315918,\n",
       "    4.772154331207275],\n",
       "   'val_dense_vowel_accuracy': [0.6854439377784729,\n",
       "    0.75022292137146,\n",
       "    0.7966210842132568,\n",
       "    0.20446889102458954,\n",
       "    0.18390804529190063,\n",
       "    0.20446889102458954,\n",
       "    0.18390804529190063,\n",
       "    0.18390804529190063,\n",
       "    0.18390804529190063,\n",
       "    0.12869104743003845],\n",
       "   'val_dense_vowel_loss': [0.8979244232177734,\n",
       "    0.7300342321395874,\n",
       "    0.6152505278587341,\n",
       "    2.171931028366089,\n",
       "    2.1497926712036133,\n",
       "    2.149296522140503,\n",
       "    2.1726303100585938,\n",
       "    2.199838161468506,\n",
       "    2.164264678955078,\n",
       "    2.175640344619751],\n",
       "   'val_loss': [5.854254639436931,\n",
       "    4.739547931151026,\n",
       "    4.096032792407749,\n",
       "    8.197775807117972,\n",
       "    8.133577982206644,\n",
       "    8.130616385739236,\n",
       "    8.179769855428205,\n",
       "    8.219748488315457,\n",
       "    8.184191869734962,\n",
       "    8.158621960389345]}),\n",
       " 'model_3': ('tanh',\n",
       "  0.2,\n",
       "  'nadam',\n",
       "  'exp',\n",
       "  {'dense_consonant_accuracy': [0.6368610262870789,\n",
       "    0.6689804792404175,\n",
       "    0.6399829387664795,\n",
       "    0.6249038577079773,\n",
       "    0.624896764755249,\n",
       "    0.6249537467956543,\n",
       "    0.6248682737350464,\n",
       "    0.6250676512718201,\n",
       "    0.6249323487281799,\n",
       "    0.6252028942108154],\n",
       "   'dense_consonant_loss': [1.0841201543807983,\n",
       "    0.9503790736198425,\n",
       "    1.1431831121444702,\n",
       "    1.2195652723312378,\n",
       "    1.2172669172286987,\n",
       "    1.2149431705474854,\n",
       "    1.213241696357727,\n",
       "    1.2117148637771606,\n",
       "    1.2115821838378906,\n",
       "    1.2108975648880005],\n",
       "   'dense_root_accuracy': [0.03864981606602669,\n",
       "    0.07310266047716141,\n",
       "    0.04020361602306366,\n",
       "    0.022554464638233185,\n",
       "    0.024170583114027977,\n",
       "    0.022853480651974678,\n",
       "    0.023458635434508324,\n",
       "    0.023850206285715103,\n",
       "    0.0246262289583683,\n",
       "    0.0240851491689682],\n",
       "   'dense_root_loss': [4.606263160705566,\n",
       "    4.230986595153809,\n",
       "    4.6494903564453125,\n",
       "    4.848083972930908,\n",
       "    4.842711448669434,\n",
       "    4.8378214836120605,\n",
       "    4.835970401763916,\n",
       "    4.83688497543335,\n",
       "    4.8367390632629395,\n",
       "    4.8377885818481445],\n",
       "   'dense_vowel_accuracy': [0.4584329426288605,\n",
       "    0.5459205508232117,\n",
       "    0.30104655027389526,\n",
       "    0.18840239942073822,\n",
       "    0.18891499936580658,\n",
       "    0.1895771026611328,\n",
       "    0.19337889552116394,\n",
       "    0.19251032173633575,\n",
       "    0.19272390007972717,\n",
       "    0.19368503987789154],\n",
       "   'dense_vowel_loss': [1.5273164510726929,\n",
       "    1.2917734384536743,\n",
       "    1.906569480895996,\n",
       "    2.167330265045166,\n",
       "    2.162139415740967,\n",
       "    2.1591644287109375,\n",
       "    2.156231641769409,\n",
       "    2.155449390411377,\n",
       "    2.1547598838806152,\n",
       "    2.1535544395446777],\n",
       "   'loss': [7.2176994369763925,\n",
       "    6.472977868549576,\n",
       "    7.700055640670253,\n",
       "    8.235119321267183,\n",
       "    8.222207578240544,\n",
       "    8.211836194442103,\n",
       "    8.205529353578902,\n",
       "    8.204032714927399,\n",
       "    8.203207185569523,\n",
       "    8.202208508118492],\n",
       "   'lr': [0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026],\n",
       "   'val_dense_consonant_accuracy': [0.6815051436424255,\n",
       "    0.7005549073219299,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149],\n",
       "   'val_dense_consonant_loss': [0.899556040763855,\n",
       "    0.8367127180099487,\n",
       "    1.2156497240066528,\n",
       "    1.2164512872695923,\n",
       "    1.2202110290527344,\n",
       "    1.2051836252212524,\n",
       "    1.221177577972412,\n",
       "    1.219954490661621,\n",
       "    1.240153193473816,\n",
       "    1.2108579874038696],\n",
       "   'val_dense_root_accuracy': [0.06975822150707245,\n",
       "    0.08291220664978027,\n",
       "    0.027199761942029,\n",
       "    0.025069361552596092,\n",
       "    0.022121481597423553,\n",
       "    0.022121481597423553,\n",
       "    0.025069361552596092,\n",
       "    0.02992469258606434,\n",
       "    0.027199761942029,\n",
       "    0.017464328557252884],\n",
       "   'val_dense_root_loss': [4.162173271179199,\n",
       "    3.9812722206115723,\n",
       "    4.851775169372559,\n",
       "    4.812920093536377,\n",
       "    4.8135199546813965,\n",
       "    4.83963680267334,\n",
       "    4.798985481262207,\n",
       "    4.835487365722656,\n",
       "    4.793559551239014,\n",
       "    4.825561046600342],\n",
       "   'val_dense_vowel_accuracy': [0.656708300113678,\n",
       "    0.6461058259010315,\n",
       "    0.20446889102458954,\n",
       "    0.18390804529190063,\n",
       "    0.18390804529190063,\n",
       "    0.20446889102458954,\n",
       "    0.20446889102458954,\n",
       "    0.18390804529190063,\n",
       "    0.18390804529190063,\n",
       "    0.20446889102458954],\n",
       "   'val_dense_vowel_loss': [0.9849834442138672,\n",
       "    0.9886292219161987,\n",
       "    2.1879923343658447,\n",
       "    2.1684694290161133,\n",
       "    2.17213773727417,\n",
       "    2.1470179557800293,\n",
       "    2.164522409439087,\n",
       "    2.1729063987731934,\n",
       "    2.179835796356201,\n",
       "    2.177403211593628],\n",
       "   'val_loss': [6.046547370159196,\n",
       "    5.8065638186862625,\n",
       "    8.2560338830362,\n",
       "    8.19818453272798,\n",
       "    8.206153001002834,\n",
       "    8.191980067104561,\n",
       "    8.185025183775574,\n",
       "    8.228697670956619,\n",
       "    8.213778530185865,\n",
       "    8.214326439516157]}),\n",
       " 'model_4': ('tanh',\n",
       "  0.4,\n",
       "  'adam',\n",
       "  'exp',\n",
       "  {'dense_consonant_accuracy': [0.6691925525665283,\n",
       "    0.7749907374382019,\n",
       "    0.8200481534004211,\n",
       "    0.8383761644363403,\n",
       "    0.8472978472709656,\n",
       "    0.8508322834968567,\n",
       "    0.8538323640823364,\n",
       "    0.8569464087486267,\n",
       "    0.8562195301055908,\n",
       "    0.8560556173324585],\n",
       "   'dense_consonant_loss': [0.9803644418716431,\n",
       "    0.6439511179924011,\n",
       "    0.533479630947113,\n",
       "    0.48212048411369324,\n",
       "    0.45836225152015686,\n",
       "    0.4484354853630066,\n",
       "    0.4400292634963989,\n",
       "    0.4305652678012848,\n",
       "    0.4291445016860962,\n",
       "    0.4325959086418152],\n",
       "   'dense_root_accuracy': [0.04082707315683365,\n",
       "    0.14762134850025177,\n",
       "    0.2953495979309082,\n",
       "    0.38916996121406555,\n",
       "    0.4417809247970581,\n",
       "    0.46739161014556885,\n",
       "    0.49126356840133667,\n",
       "    0.5036770105361938,\n",
       "    0.5155203342437744,\n",
       "    0.509833812713623],\n",
       "   'dense_root_loss': [4.571709632873535,\n",
       "    3.558694362640381,\n",
       "    2.6960859298706055,\n",
       "    2.273087739944458,\n",
       "    2.0582327842712402,\n",
       "    1.9583179950714111,\n",
       "    1.8673300743103027,\n",
       "    1.8188612461090088,\n",
       "    1.7820773124694824,\n",
       "    1.7987054586410522],\n",
       "   'dense_vowel_accuracy': [0.5245261192321777,\n",
       "    0.7334820032119751,\n",
       "    0.7753185033798218,\n",
       "    0.7956275343894958,\n",
       "    0.8074922561645508,\n",
       "    0.8083829879760742,\n",
       "    0.8117393255233765,\n",
       "    0.8145469427108765,\n",
       "    0.8163070678710938,\n",
       "    0.8163782954216003],\n",
       "   'dense_vowel_loss': [1.365631341934204,\n",
       "    0.8096767663955688,\n",
       "    0.6909680366516113,\n",
       "    0.627878725528717,\n",
       "    0.5956601500511169,\n",
       "    0.5916104912757874,\n",
       "    0.5774439573287964,\n",
       "    0.571513295173645,\n",
       "    0.566848874092102,\n",
       "    0.5690808892250061],\n",
       "   'loss': [6.917705633166927,\n",
       "    5.01089561433751,\n",
       "    3.92042490380814,\n",
       "    3.3825474071029693,\n",
       "    3.112502285560432,\n",
       "    2.997170496064411,\n",
       "    2.884883088403365,\n",
       "    2.821095350323295,\n",
       "    2.7783760707041245,\n",
       "    2.8007468837793708],\n",
       "   'lr': [0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513],\n",
       "   'val_dense_consonant_accuracy': [0.7800980806350708,\n",
       "    0.8654131889343262,\n",
       "    0.892315685749054,\n",
       "    0.9006391167640686,\n",
       "    0.9036861062049866,\n",
       "    0.9119599461555481,\n",
       "    0.9155271649360657,\n",
       "    0.9155271649360657,\n",
       "    0.9129756093025208,\n",
       "    0.9164437055587769],\n",
       "   'val_dense_consonant_loss': [0.5775768160820007,\n",
       "    0.39295676350593567,\n",
       "    0.33212265372276306,\n",
       "    0.30501800775527954,\n",
       "    0.2953811287879944,\n",
       "    0.2683678865432739,\n",
       "    0.2620307207107544,\n",
       "    0.25777456164360046,\n",
       "    0.26240038871765137,\n",
       "    0.2580454647541046],\n",
       "   'val_dense_root_accuracy': [0.0951743945479393,\n",
       "    0.3151753842830658,\n",
       "    0.4703477919101715,\n",
       "    0.5592300891876221,\n",
       "    0.587049126625061,\n",
       "    0.6214823722839355,\n",
       "    0.6475425958633423,\n",
       "    0.6613406538963318,\n",
       "    0.660250723361969,\n",
       "    0.6606222987174988],\n",
       "   'val_dense_root_loss': [3.9248926639556885,\n",
       "    2.547297239303589,\n",
       "    1.880446195602417,\n",
       "    1.5572359561920166,\n",
       "    1.4329555034637451,\n",
       "    1.3172160387039185,\n",
       "    1.2277244329452515,\n",
       "    1.2022557258605957,\n",
       "    1.1852765083312988,\n",
       "    1.192442536354065],\n",
       "   'val_dense_vowel_accuracy': [0.8102457523345947,\n",
       "    0.863084614276886,\n",
       "    0.8824564218521118,\n",
       "    0.8969480991363525,\n",
       "    0.8980380296707153,\n",
       "    0.9067330360412598,\n",
       "    0.9102259278297424,\n",
       "    0.9066091775894165,\n",
       "    0.9124306440353394,\n",
       "    0.9111672639846802],\n",
       "   'val_dense_vowel_loss': [0.5755183696746826,\n",
       "    0.44098034501075745,\n",
       "    0.37686893343925476,\n",
       "    0.3396792709827423,\n",
       "    0.3214971423149109,\n",
       "    0.31292057037353516,\n",
       "    0.29610347747802734,\n",
       "    0.30362018942832947,\n",
       "    0.29267287254333496,\n",
       "    0.29131489992141724],\n",
       "   'val_loss': [5.078470833945076,\n",
       "    3.381886835472479,\n",
       "    2.5897072538987445,\n",
       "    2.2023288610196046,\n",
       "    2.0501651483729297,\n",
       "    1.8989004328096852,\n",
       "    1.786247753265402,\n",
       "    1.764242052370435,\n",
       "    1.7407021892954326,\n",
       "    1.7423296066867044]}),\n",
       " 'model_5': ('tanh',\n",
       "  0.4,\n",
       "  'adam',\n",
       "  'exp',\n",
       "  {'dense_consonant_accuracy': [0.6831881999969482,\n",
       "    0.7643314599990845,\n",
       "    0.7903246283531189,\n",
       "    0.7998433709144592,\n",
       "    0.8004627823829651,\n",
       "    0.803153932094574,\n",
       "    0.8001495003700256,\n",
       "    0.7976149916648865,\n",
       "    0.7952868938446045,\n",
       "    0.7908443808555603],\n",
       "   'dense_consonant_loss': [0.9248408675193787,\n",
       "    0.6768046617507935,\n",
       "    0.6099839210510254,\n",
       "    0.5884692072868347,\n",
       "    0.5844443440437317,\n",
       "    0.5776143670082092,\n",
       "    0.5837028622627258,\n",
       "    0.5904303193092346,\n",
       "    0.5997111797332764,\n",
       "    0.6127039790153503],\n",
       "   'dense_root_accuracy': [0.0519694909453392,\n",
       "    0.14945180714130402,\n",
       "    0.2300797402858734,\n",
       "    0.2711590528488159,\n",
       "    0.29243913292884827,\n",
       "    0.3072262704372406,\n",
       "    0.3168090581893921,\n",
       "    0.3176420331001282,\n",
       "    0.3070696294307709,\n",
       "    0.3066994249820709],\n",
       "   'dense_root_loss': [4.433084964752197,\n",
       "    3.5343527793884277,\n",
       "    3.045389175415039,\n",
       "    2.8344461917877197,\n",
       "    2.743638038635254,\n",
       "    2.674077272415161,\n",
       "    2.6321990489959717,\n",
       "    2.6527369022369385,\n",
       "    2.706040859222412,\n",
       "    2.708946466445923],\n",
       "   'dense_vowel_accuracy': [0.5690744519233704,\n",
       "    0.7083796262741089,\n",
       "    0.7367079854011536,\n",
       "    0.7379609942436218,\n",
       "    0.7457283139228821,\n",
       "    0.7467036843299866,\n",
       "    0.7473016977310181,\n",
       "    0.738010823726654,\n",
       "    0.7286416292190552,\n",
       "    0.7292823791503906],\n",
       "   'dense_vowel_loss': [1.248612880706787,\n",
       "    0.8641750812530518,\n",
       "    0.7963583469390869,\n",
       "    0.7907280921936035,\n",
       "    0.7677573561668396,\n",
       "    0.764240562915802,\n",
       "    0.7575225830078125,\n",
       "    0.7894336581230164,\n",
       "    0.8133227229118347,\n",
       "    0.8074884414672852],\n",
       "   'loss': [6.606540639109516,\n",
       "    5.07509260961138,\n",
       "    4.451884964024021,\n",
       "    4.213268436136942,\n",
       "    4.0959538512601315,\n",
       "    4.0157697032459705,\n",
       "    3.973498008544164,\n",
       "    4.032908889769693,\n",
       "    4.118940134481641,\n",
       "    4.129021250330857],\n",
       "   'lr': [0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513],\n",
       "   'val_dense_consonant_accuracy': [0.785969078540802,\n",
       "    0.847750723361969,\n",
       "    0.8657600283622742,\n",
       "    0.8705162405967712,\n",
       "    0.8664536476135254,\n",
       "    0.8588981628417969,\n",
       "    0.8729439377784729,\n",
       "    0.8657600283622742,\n",
       "    0.8652893304824829,\n",
       "    0.8492618203163147],\n",
       "   'val_dense_consonant_loss': [0.5856812000274658,\n",
       "    0.4417532980442047,\n",
       "    0.3933160603046417,\n",
       "    0.3826565742492676,\n",
       "    0.4047029912471771,\n",
       "    0.3978138864040375,\n",
       "    0.3812042474746704,\n",
       "    0.4012116491794586,\n",
       "    0.411536306142807,\n",
       "    0.44006043672561646],\n",
       "   'val_dense_root_accuracy': [0.12809650599956512,\n",
       "    0.2789338231086731,\n",
       "    0.3678904175758362,\n",
       "    0.40559354424476624,\n",
       "    0.4050237834453583,\n",
       "    0.44290032982826233,\n",
       "    0.46586406230926514,\n",
       "    0.4213238060474396,\n",
       "    0.42996928095817566,\n",
       "    0.4062376022338867],\n",
       "   'val_dense_root_loss': [3.6064834594726562,\n",
       "    2.724623203277588,\n",
       "    2.3117361068725586,\n",
       "    2.159069299697876,\n",
       "    2.1445255279541016,\n",
       "    1.9956257343292236,\n",
       "    1.9241682291030884,\n",
       "    2.1064000129699707,\n",
       "    2.06792950630188,\n",
       "    2.1851003170013428],\n",
       "   'val_dense_vowel_accuracy': [0.7934998273849487,\n",
       "    0.831946074962616,\n",
       "    0.8572879433631897,\n",
       "    0.8494599461555481,\n",
       "    0.8592201471328735,\n",
       "    0.8651406764984131,\n",
       "    0.8623909950256348,\n",
       "    0.8474534153938293,\n",
       "    0.849534273147583,\n",
       "    0.8403686285018921],\n",
       "   'val_dense_vowel_loss': [0.6122921109199524,\n",
       "    0.5176458358764648,\n",
       "    0.4463450610637665,\n",
       "    0.4605182707309723,\n",
       "    0.4545946717262268,\n",
       "    0.4259546995162964,\n",
       "    0.43852102756500244,\n",
       "    0.480750173330307,\n",
       "    0.47446373105049133,\n",
       "    0.4927724003791809],\n",
       "   'val_loss': [4.804642104837945,\n",
       "    3.6842083414064906,\n",
       "    3.1517476966538887,\n",
       "    3.0018980587185538,\n",
       "    3.0036022907866404,\n",
       "    2.8191523928043156,\n",
       "    2.7439826623438086,\n",
       "    2.988316648780378,\n",
       "    2.953148071415312,\n",
       "    3.118041032843301]})}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train\n",
    "del x_test\n",
    "del y_train_root\n",
    "del y_test_root\n",
    "del y_train_vowel\n",
    "del y_test_vowel\n",
    "del y_train_consonant\n",
    "del y_test_consonant\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
