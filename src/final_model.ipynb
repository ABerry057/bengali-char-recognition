{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9cf91b3d7f90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "import time, gc\n",
    "import cv2\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import clone_model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = os.path.dirname(os.getcwd())\n",
    "\n",
    "def get_dummies(df):\n",
    "    cols = []\n",
    "    for col in df:\n",
    "        cols.append(pd.get_dummies(df[col].astype(str)))\n",
    "    return pd.concat(cols, axis=1)\n",
    "\n",
    "# IMG_SIZE=64\n",
    "global IMG_X_SIZE\n",
    "IMG_X_SIZE = 87\n",
    "global IMG_Y_SIZE\n",
    "IMG_Y_SIZE = 106\n",
    "global N_CHANNELS\n",
    "N_CHANNELS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the preprocessed data for fitting in the model\n",
    "# this is for GCP or local\n",
    "proc_img_0 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_0.parquet\").to_pandas()\n",
    "proc_img_1 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_1.parquet\").to_pandas()\n",
    "proc_img_2 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_2.parquet\").to_pandas()\n",
    "proc_img_3 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_3.parquet\").to_pandas()\n",
    "train_images = pd.concat([proc_img_0, proc_img_1, proc_img_2, proc_img_3])\n",
    "train_images.drop(columns=['image_id'],inplace=True)\n",
    "del proc_img_0\n",
    "del proc_img_1\n",
    "del proc_img_2\n",
    "del proc_img_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN takes images in shape `(batch_size, h, w, channels)`, so reshape the images\n",
    "train_images = train_images.values.reshape(-1, IMG_X_SIZE, IMG_Y_SIZE, N_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(parent_directory+\"/data/train.csv\")\n",
    "Y_train_root = pd.get_dummies(train_labels['grapheme_root']).values\n",
    "Y_train_vowel = pd.get_dummies(train_labels['vowel_diacritic']).values\n",
    "Y_train_consonant = pd.get_dummies(train_labels['consonant_diacritic']).values\n",
    "del train_labels\n",
    "# print(f'Training images: {train_images.shape}')\n",
    "# print(f'Training labels root: {Y_train_root.shape}')\n",
    "# print(f'Training labels vowel: {Y_train_vowel.shape}')\n",
    "# print(f'Training labels consonants: {Y_train_consonant.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below this should take around 5 minutes\n",
    "x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant \\\n",
    "    = train_test_split(train_images, Y_train_root, Y_train_vowel, Y_train_consonant, test_size=0.3, random_state=666)\n",
    "del train_images\n",
    "x_val, x_test, y_val_root, y_test_root, y_val_vowel, y_test_vowel, y_val_consonant, y_test_consonant \\\n",
    "    = train_test_split(x_test, y_test_root, y_test_vowel, y_test_consonant, test_size=0.33, random_state=666)\n",
    "# print(f'x_train size: {x_train.shape}')\n",
    "# print(f'x_val size: {x_val.shape}')\n",
    "# print(f'x_test size: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n",
    "\n",
    "    def flow(self,\n",
    "             x,\n",
    "             y=None,\n",
    "             batch_size=32,\n",
    "             shuffle=True,\n",
    "             sample_weight=None,\n",
    "             seed=None,\n",
    "             save_to_dir=None,\n",
    "             save_prefix='',\n",
    "             save_format='png',\n",
    "             subset=None):\n",
    "\n",
    "        targets = None\n",
    "        target_lengths = {}\n",
    "        ordered_outputs = []\n",
    "        for output, target in y.items():\n",
    "            if targets is None:\n",
    "                targets = target\n",
    "            else:\n",
    "                targets = np.concatenate((targets, target), axis=1)\n",
    "            target_lengths[output] = target.shape[1]\n",
    "            ordered_outputs.append(output)\n",
    "\n",
    "\n",
    "        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n",
    "                                         shuffle=shuffle):\n",
    "            target_dict = {}\n",
    "            i = 0\n",
    "            for output in ordered_outputs:\n",
    "                target_length = target_lengths[output]\n",
    "                target_dict[output] = flowy[:, i: i + target_length]\n",
    "                i += target_length\n",
    "\n",
    "            yield flowx, target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data generator (should take two minutes)\n",
    "# Data augmentation for creating more training data\n",
    "datagen = MultiOutputDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.15, # Randomly zoom image \n",
    "    width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "# This will just calculate parameters required to augment the given data. This won't perform any augmentations\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction_root = ReduceLROnPlateau(monitor='dense_3_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "learning_rate_reduction_vowel = ReduceLROnPlateau(monitor='dense_4_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "learning_rate_reduction_consonant = ReduceLROnPlateau(monitor='dense_5_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model has 5 convolutional layers\n",
    "def build_model(activation, dropout_prob):\n",
    "    inputs = Input(shape = (IMG_X_SIZE, IMG_Y_SIZE, N_CHANNELS))\n",
    "    # first convolutional layer\n",
    "    model = Conv2D(filters=16, kernel_size=(3, 3), padding='SAME', activation=activation, input_shape=(IMG_X_SIZE, IMG_Y_SIZE, N_CHANNELS))(inputs)\n",
    "    model = Conv2D(filters=16, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=16, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=16, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=16, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 2nd convolutional layer\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(inputs)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 3rd CL\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 4th CL\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 5th CL\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # dense layer\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(1024, activation=activation)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    dense = Dense(512, activation=activation)(model)\n",
    "    # softmax layer\n",
    "    head_root = Dense(168, activation = 'softmax', name = \"dense_root\")(dense)\n",
    "    head_vowel = Dense(11, activation = 'softmax', name = \"dense_vowel\")(dense)\n",
    "    head_consonant = Dense(7, activation = 'softmax', name = \"dense_consonant\")(dense)\n",
    "    # output\n",
    "    model = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file=f'{parent_directory}/figures/final_model_architecture.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = 'relu'\n",
    "dropout_prob = 0.2\n",
    "optimizer = 'adam'\n",
    "batch_size = 256\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "549/549 [==============================] - 241s 440ms/step - loss: 5.9220 - dense_root_loss: 3.9675 - dense_vowel_loss: 1.1389 - dense_consonant_loss: 0.8156 - dense_root_accuracy: 0.1061 - dense_vowel_accuracy: 0.6090 - dense_consonant_accuracy: 0.7215 - val_loss: 2.9967 - val_dense_root_loss: 2.2227 - val_dense_vowel_loss: 0.4210 - val_dense_consonant_loss: 0.3523 - val_dense_root_accuracy: 0.3742 - val_dense_vowel_accuracy: 0.8616 - val_dense_consonant_accuracy: 0.8759\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_3_accuracy` which is not available. Available metrics are: val_loss,val_dense_root_loss,val_dense_vowel_loss,val_dense_consonant_loss,val_dense_root_accuracy,val_dense_vowel_accuracy,val_dense_consonant_accuracy,loss,dense_root_loss,dense_vowel_loss,dense_consonant_loss,dense_root_accuracy,dense_vowel_accuracy,dense_consonant_accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/opt/conda/lib/python3.7/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_4_accuracy` which is not available. Available metrics are: val_loss,val_dense_root_loss,val_dense_vowel_loss,val_dense_consonant_loss,val_dense_root_accuracy,val_dense_vowel_accuracy,val_dense_consonant_accuracy,loss,dense_root_loss,dense_vowel_loss,dense_consonant_loss,dense_root_accuracy,dense_vowel_accuracy,dense_consonant_accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/opt/conda/lib/python3.7/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_5_accuracy` which is not available. Available metrics are: val_loss,val_dense_root_loss,val_dense_vowel_loss,val_dense_consonant_loss,val_dense_root_accuracy,val_dense_vowel_accuracy,val_dense_consonant_accuracy,loss,dense_root_loss,dense_vowel_loss,dense_consonant_loss,dense_root_accuracy,dense_vowel_accuracy,dense_consonant_accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 229s 417ms/step - loss: 2.7054 - dense_root_loss: 1.7821 - dense_vowel_loss: 0.5392 - dense_consonant_loss: 0.3841 - dense_root_accuracy: 0.5048 - dense_vowel_accuracy: 0.8262 - dense_consonant_accuracy: 0.8745 - val_loss: 1.2246 - val_dense_root_loss: 0.8153 - val_dense_vowel_loss: 0.2180 - val_dense_consonant_loss: 0.1912 - val_dense_root_accuracy: 0.7642 - val_dense_vowel_accuracy: 0.9361 - val_dense_consonant_accuracy: 0.9417\n",
      "Epoch 3/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 1.6457 - dense_root_loss: 0.9982 - dense_vowel_loss: 0.3825 - dense_consonant_loss: 0.2651 - dense_root_accuracy: 0.7183 - dense_vowel_accuracy: 0.8816 - dense_consonant_accuracy: 0.9149 - val_loss: 0.8049 - val_dense_root_loss: 0.5142 - val_dense_vowel_loss: 0.1577 - val_dense_consonant_loss: 0.1327 - val_dense_root_accuracy: 0.8521 - val_dense_vowel_accuracy: 0.9556 - val_dense_consonant_accuracy: 0.9590\n",
      "Epoch 4/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 1.2762 - dense_root_loss: 0.7511 - dense_vowel_loss: 0.3068 - dense_consonant_loss: 0.2183 - dense_root_accuracy: 0.7890 - dense_vowel_accuracy: 0.9072 - dense_consonant_accuracy: 0.9310 - val_loss: 0.6763 - val_dense_root_loss: 0.4291 - val_dense_vowel_loss: 0.1249 - val_dense_consonant_loss: 0.1220 - val_dense_root_accuracy: 0.8796 - val_dense_vowel_accuracy: 0.9646 - val_dense_consonant_accuracy: 0.9640\n",
      "Epoch 5/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 1.0874 - dense_root_loss: 0.6267 - dense_vowel_loss: 0.2700 - dense_consonant_loss: 0.1906 - dense_root_accuracy: 0.8238 - dense_vowel_accuracy: 0.9195 - dense_consonant_accuracy: 0.9402 - val_loss: 0.5913 - val_dense_root_loss: 0.3766 - val_dense_vowel_loss: 0.1052 - val_dense_consonant_loss: 0.1093 - val_dense_root_accuracy: 0.8947 - val_dense_vowel_accuracy: 0.9719 - val_dense_consonant_accuracy: 0.9669\n",
      "Epoch 6/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.9754 - dense_root_loss: 0.5539 - dense_vowel_loss: 0.2471 - dense_consonant_loss: 0.1744 - dense_root_accuracy: 0.8423 - dense_vowel_accuracy: 0.9267 - dense_consonant_accuracy: 0.9459 - val_loss: 0.5342 - val_dense_root_loss: 0.3399 - val_dense_vowel_loss: 0.1062 - val_dense_consonant_loss: 0.0879 - val_dense_root_accuracy: 0.9051 - val_dense_vowel_accuracy: 0.9718 - val_dense_consonant_accuracy: 0.9734\n",
      "Epoch 7/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.9093 - dense_root_loss: 0.5109 - dense_vowel_loss: 0.2345 - dense_consonant_loss: 0.1639 - dense_root_accuracy: 0.8559 - dense_vowel_accuracy: 0.9309 - dense_consonant_accuracy: 0.9494 - val_loss: 0.5142 - val_dense_root_loss: 0.3239 - val_dense_vowel_loss: 0.0983 - val_dense_consonant_loss: 0.0919 - val_dense_root_accuracy: 0.9088 - val_dense_vowel_accuracy: 0.9737 - val_dense_consonant_accuracy: 0.9725\n",
      "Epoch 8/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.8448 - dense_root_loss: 0.4706 - dense_vowel_loss: 0.2197 - dense_consonant_loss: 0.1546 - dense_root_accuracy: 0.8665 - dense_vowel_accuracy: 0.9355 - dense_consonant_accuracy: 0.9516 - val_loss: 0.4831 - val_dense_root_loss: 0.2976 - val_dense_vowel_loss: 0.0998 - val_dense_consonant_loss: 0.0855 - val_dense_root_accuracy: 0.9164 - val_dense_vowel_accuracy: 0.9750 - val_dense_consonant_accuracy: 0.9743\n",
      "Epoch 9/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.7839 - dense_root_loss: 0.4345 - dense_vowel_loss: 0.2052 - dense_consonant_loss: 0.1442 - dense_root_accuracy: 0.8764 - dense_vowel_accuracy: 0.9398 - dense_consonant_accuracy: 0.9555 - val_loss: 0.4848 - val_dense_root_loss: 0.3036 - val_dense_vowel_loss: 0.0971 - val_dense_consonant_loss: 0.0841 - val_dense_root_accuracy: 0.9172 - val_dense_vowel_accuracy: 0.9766 - val_dense_consonant_accuracy: 0.9761\n",
      "Epoch 10/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.7497 - dense_root_loss: 0.4092 - dense_vowel_loss: 0.2003 - dense_consonant_loss: 0.1401 - dense_root_accuracy: 0.8833 - dense_vowel_accuracy: 0.9406 - dense_consonant_accuracy: 0.9571 - val_loss: 0.4739 - val_dense_root_loss: 0.2946 - val_dense_vowel_loss: 0.0979 - val_dense_consonant_loss: 0.0814 - val_dense_root_accuracy: 0.9191 - val_dense_vowel_accuracy: 0.9747 - val_dense_consonant_accuracy: 0.9755\n",
      "Epoch 11/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.7201 - dense_root_loss: 0.3931 - dense_vowel_loss: 0.1937 - dense_consonant_loss: 0.1334 - dense_root_accuracy: 0.8876 - dense_vowel_accuracy: 0.9435 - dense_consonant_accuracy: 0.9589 - val_loss: 0.4408 - val_dense_root_loss: 0.2709 - val_dense_vowel_loss: 0.0895 - val_dense_consonant_loss: 0.0801 - val_dense_root_accuracy: 0.9271 - val_dense_vowel_accuracy: 0.9762 - val_dense_consonant_accuracy: 0.9771\n",
      "Epoch 12/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.6831 - dense_root_loss: 0.3693 - dense_vowel_loss: 0.1862 - dense_consonant_loss: 0.1276 - dense_root_accuracy: 0.8938 - dense_vowel_accuracy: 0.9461 - dense_consonant_accuracy: 0.9611 - val_loss: 0.4425 - val_dense_root_loss: 0.2747 - val_dense_vowel_loss: 0.0888 - val_dense_consonant_loss: 0.0787 - val_dense_root_accuracy: 0.9266 - val_dense_vowel_accuracy: 0.9769 - val_dense_consonant_accuracy: 0.9772\n",
      "Epoch 13/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.6603 - dense_root_loss: 0.3581 - dense_vowel_loss: 0.1794 - dense_consonant_loss: 0.1228 - dense_root_accuracy: 0.8976 - dense_vowel_accuracy: 0.9471 - dense_consonant_accuracy: 0.9625 - val_loss: 0.4138 - val_dense_root_loss: 0.2602 - val_dense_vowel_loss: 0.0799 - val_dense_consonant_loss: 0.0735 - val_dense_root_accuracy: 0.9305 - val_dense_vowel_accuracy: 0.9795 - val_dense_consonant_accuracy: 0.9783\n",
      "Epoch 14/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.6234 - dense_root_loss: 0.3370 - dense_vowel_loss: 0.1698 - dense_consonant_loss: 0.1166 - dense_root_accuracy: 0.9026 - dense_vowel_accuracy: 0.9506 - dense_consonant_accuracy: 0.9643 - val_loss: 0.4359 - val_dense_root_loss: 0.2700 - val_dense_vowel_loss: 0.0875 - val_dense_consonant_loss: 0.0784 - val_dense_root_accuracy: 0.9252 - val_dense_vowel_accuracy: 0.9775 - val_dense_consonant_accuracy: 0.9780\n",
      "Epoch 15/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.6049 - dense_root_loss: 0.3223 - dense_vowel_loss: 0.1659 - dense_consonant_loss: 0.1167 - dense_root_accuracy: 0.9063 - dense_vowel_accuracy: 0.9517 - dense_consonant_accuracy: 0.9654 - val_loss: 0.4010 - val_dense_root_loss: 0.2496 - val_dense_vowel_loss: 0.0810 - val_dense_consonant_loss: 0.0703 - val_dense_root_accuracy: 0.9316 - val_dense_vowel_accuracy: 0.9795 - val_dense_consonant_accuracy: 0.9794\n",
      "Epoch 16/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.5837 - dense_root_loss: 0.3148 - dense_vowel_loss: 0.1585 - dense_consonant_loss: 0.1105 - dense_root_accuracy: 0.9095 - dense_vowel_accuracy: 0.9539 - dense_consonant_accuracy: 0.9665 - val_loss: 0.4087 - val_dense_root_loss: 0.2479 - val_dense_vowel_loss: 0.0868 - val_dense_consonant_loss: 0.0739 - val_dense_root_accuracy: 0.9336 - val_dense_vowel_accuracy: 0.9775 - val_dense_consonant_accuracy: 0.9790\n",
      "Epoch 17/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.5717 - dense_root_loss: 0.3042 - dense_vowel_loss: 0.1598 - dense_consonant_loss: 0.1077 - dense_root_accuracy: 0.9116 - dense_vowel_accuracy: 0.9532 - dense_consonant_accuracy: 0.9672 - val_loss: 0.3905 - val_dense_root_loss: 0.2432 - val_dense_vowel_loss: 0.0746 - val_dense_consonant_loss: 0.0726 - val_dense_root_accuracy: 0.9344 - val_dense_vowel_accuracy: 0.9820 - val_dense_consonant_accuracy: 0.9793\n",
      "Epoch 18/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.5400 - dense_root_loss: 0.2855 - dense_vowel_loss: 0.1508 - dense_consonant_loss: 0.1037 - dense_root_accuracy: 0.9173 - dense_vowel_accuracy: 0.9558 - dense_consonant_accuracy: 0.9691 - val_loss: 0.3900 - val_dense_root_loss: 0.2467 - val_dense_vowel_loss: 0.0750 - val_dense_consonant_loss: 0.0684 - val_dense_root_accuracy: 0.9351 - val_dense_vowel_accuracy: 0.9810 - val_dense_consonant_accuracy: 0.9799\n",
      "Epoch 19/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.5341 - dense_root_loss: 0.2827 - dense_vowel_loss: 0.1512 - dense_consonant_loss: 0.1002 - dense_root_accuracy: 0.9173 - dense_vowel_accuracy: 0.9554 - dense_consonant_accuracy: 0.9692 - val_loss: 0.3902 - val_dense_root_loss: 0.2363 - val_dense_vowel_loss: 0.0828 - val_dense_consonant_loss: 0.0710 - val_dense_root_accuracy: 0.9353 - val_dense_vowel_accuracy: 0.9787 - val_dense_consonant_accuracy: 0.9800\n",
      "Epoch 20/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.5134 - dense_root_loss: 0.2691 - dense_vowel_loss: 0.1443 - dense_consonant_loss: 0.1000 - dense_root_accuracy: 0.9220 - dense_vowel_accuracy: 0.9575 - dense_consonant_accuracy: 0.9697 - val_loss: 0.3792 - val_dense_root_loss: 0.2408 - val_dense_vowel_loss: 0.0721 - val_dense_consonant_loss: 0.0661 - val_dense_root_accuracy: 0.9362 - val_dense_vowel_accuracy: 0.9818 - val_dense_consonant_accuracy: 0.9814\n",
      "Epoch 21/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.4914 - dense_root_loss: 0.2565 - dense_vowel_loss: 0.1409 - dense_consonant_loss: 0.0940 - dense_root_accuracy: 0.9248 - dense_vowel_accuracy: 0.9583 - dense_consonant_accuracy: 0.9715 - val_loss: 0.3726 - val_dense_root_loss: 0.2378 - val_dense_vowel_loss: 0.0691 - val_dense_consonant_loss: 0.0655 - val_dense_root_accuracy: 0.9384 - val_dense_vowel_accuracy: 0.9830 - val_dense_consonant_accuracy: 0.9824\n",
      "Epoch 22/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.4776 - dense_root_loss: 0.2454 - dense_vowel_loss: 0.1386 - dense_consonant_loss: 0.0936 - dense_root_accuracy: 0.9269 - dense_vowel_accuracy: 0.9596 - dense_consonant_accuracy: 0.9711 - val_loss: 0.3801 - val_dense_root_loss: 0.2307 - val_dense_vowel_loss: 0.0837 - val_dense_consonant_loss: 0.0655 - val_dense_root_accuracy: 0.9391 - val_dense_vowel_accuracy: 0.9800 - val_dense_consonant_accuracy: 0.9811\n",
      "Epoch 23/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.4729 - dense_root_loss: 0.2437 - dense_vowel_loss: 0.1368 - dense_consonant_loss: 0.0924 - dense_root_accuracy: 0.9282 - dense_vowel_accuracy: 0.9593 - dense_consonant_accuracy: 0.9717 - val_loss: 0.3718 - val_dense_root_loss: 0.2395 - val_dense_vowel_loss: 0.0689 - val_dense_consonant_loss: 0.0633 - val_dense_root_accuracy: 0.9381 - val_dense_vowel_accuracy: 0.9827 - val_dense_consonant_accuracy: 0.9828\n",
      "Epoch 24/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.4632 - dense_root_loss: 0.2396 - dense_vowel_loss: 0.1351 - dense_consonant_loss: 0.0885 - dense_root_accuracy: 0.9294 - dense_vowel_accuracy: 0.9603 - dense_consonant_accuracy: 0.9730 - val_loss: 0.3581 - val_dense_root_loss: 0.2248 - val_dense_vowel_loss: 0.0719 - val_dense_consonant_loss: 0.0612 - val_dense_root_accuracy: 0.9424 - val_dense_vowel_accuracy: 0.9816 - val_dense_consonant_accuracy: 0.9821\n",
      "Epoch 25/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.4454 - dense_root_loss: 0.2279 - dense_vowel_loss: 0.1299 - dense_consonant_loss: 0.0876 - dense_root_accuracy: 0.9330 - dense_vowel_accuracy: 0.9616 - dense_consonant_accuracy: 0.9730 - val_loss: 0.3642 - val_dense_root_loss: 0.2258 - val_dense_vowel_loss: 0.0736 - val_dense_consonant_loss: 0.0645 - val_dense_root_accuracy: 0.9416 - val_dense_vowel_accuracy: 0.9821 - val_dense_consonant_accuracy: 0.9820\n",
      "Epoch 26/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.4339 - dense_root_loss: 0.2208 - dense_vowel_loss: 0.1258 - dense_consonant_loss: 0.0873 - dense_root_accuracy: 0.9344 - dense_vowel_accuracy: 0.9631 - dense_consonant_accuracy: 0.9738 - val_loss: 0.3530 - val_dense_root_loss: 0.2218 - val_dense_vowel_loss: 0.0706 - val_dense_consonant_loss: 0.0603 - val_dense_root_accuracy: 0.9422 - val_dense_vowel_accuracy: 0.9821 - val_dense_consonant_accuracy: 0.9832\n",
      "Epoch 27/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.4208 - dense_root_loss: 0.2150 - dense_vowel_loss: 0.1246 - dense_consonant_loss: 0.0812 - dense_root_accuracy: 0.9363 - dense_vowel_accuracy: 0.9636 - dense_consonant_accuracy: 0.9749 - val_loss: 0.3651 - val_dense_root_loss: 0.2240 - val_dense_vowel_loss: 0.0798 - val_dense_consonant_loss: 0.0610 - val_dense_root_accuracy: 0.9424 - val_dense_vowel_accuracy: 0.9804 - val_dense_consonant_accuracy: 0.9832\n",
      "Epoch 28/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.4184 - dense_root_loss: 0.2116 - dense_vowel_loss: 0.1251 - dense_consonant_loss: 0.0817 - dense_root_accuracy: 0.9364 - dense_vowel_accuracy: 0.9625 - dense_consonant_accuracy: 0.9748 - val_loss: 0.3526 - val_dense_root_loss: 0.2202 - val_dense_vowel_loss: 0.0673 - val_dense_consonant_loss: 0.0649 - val_dense_root_accuracy: 0.9415 - val_dense_vowel_accuracy: 0.9839 - val_dense_consonant_accuracy: 0.9825\n",
      "Epoch 29/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.4045 - dense_root_loss: 0.2044 - dense_vowel_loss: 0.1201 - dense_consonant_loss: 0.0801 - dense_root_accuracy: 0.9388 - dense_vowel_accuracy: 0.9649 - dense_consonant_accuracy: 0.9756 - val_loss: 0.3487 - val_dense_root_loss: 0.2253 - val_dense_vowel_loss: 0.0655 - val_dense_consonant_loss: 0.0577 - val_dense_root_accuracy: 0.9433 - val_dense_vowel_accuracy: 0.9832 - val_dense_consonant_accuracy: 0.9840\n",
      "Epoch 30/30\n",
      "549/549 [==============================] - 229s 417ms/step - loss: 0.4044 - dense_root_loss: 0.2029 - dense_vowel_loss: 0.1220 - dense_consonant_loss: 0.0795 - dense_root_accuracy: 0.9397 - dense_vowel_accuracy: 0.9638 - dense_consonant_accuracy: 0.9755 - val_loss: 0.3470 - val_dense_root_loss: 0.2218 - val_dense_vowel_loss: 0.0667 - val_dense_consonant_loss: 0.0583 - val_dense_root_accuracy: 0.9434 - val_dense_vowel_accuracy: 0.9836 - val_dense_consonant_accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "model = build_model(activation, dropout_prob)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "callbacks=[learning_rate_reduction_root, learning_rate_reduction_vowel, learning_rate_reduction_consonant]\n",
    "history = model.fit_generator(\n",
    "    datagen.flow(\n",
    "        x_train, {'dense_root': y_train_root, 'dense_vowel': y_train_vowel, 'dense_consonant': y_train_consonant}, \n",
    "        batch_size=batch_size),\n",
    "    epochs = epochs, validation_data = (x_val, [y_val_root, y_val_vowel, y_val_consonant]), \n",
    "    steps_per_epoch=x_train.shape[0] // batch_size, \n",
    "    callbacks=callbacks\n",
    "    )\n",
    "for key in history.history.keys():\n",
    "    history.history[key] = [np.float64(val) for val in history.history[key]]\n",
    "with open(parent_directory+\"/models/final_model.json\", \"w\") as fp:\n",
    "    json.dump(history.history, fp, sort_keys = True, indent = 4)\n",
    "\n",
    "model.save(parent_directory+ \"/models/final_model_v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train\n",
    "del x_test\n",
    "del y_train_root\n",
    "del y_test_root\n",
    "del y_train_vowel\n",
    "del y_test_vowel\n",
    "del y_train_consonant\n",
    "del y_test_consonant\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
