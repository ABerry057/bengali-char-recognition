{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "import time, gc\n",
    "import cv2\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import clone_model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = os.path.dirname(os.getcwd())\n",
    "\n",
    "def get_dummies(df):\n",
    "    cols = []\n",
    "    for col in df:\n",
    "        cols.append(pd.get_dummies(df[col].astype(str)))\n",
    "    return pd.concat(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_SIZE=64\n",
    "global IMG_X_SIZE\n",
    "IMG_X_SIZE = 87\n",
    "global IMG_Y_SIZE\n",
    "IMG_Y_SIZE = 106\n",
    "global N_CHANNELS\n",
    "N_CHANNELS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the preprocessed data for fitting in the model\n",
    "# this is for GCP or local\n",
    "proc_img_0 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_0.parquet\").to_pandas()\n",
    "proc_img_1 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_1.parquet\").to_pandas()\n",
    "proc_img_2 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_2.parquet\").to_pandas()\n",
    "proc_img_3 = pq.read_table(parent_directory+\"/data/preprocessed/preprop_3.parquet\").to_pandas()\n",
    "train_images = pd.concat([proc_img_0, proc_img_1, proc_img_2, proc_img_3])\n",
    "train_images.drop(columns=['image_id'],inplace=True)\n",
    "del proc_img_0\n",
    "del proc_img_1\n",
    "del proc_img_2\n",
    "del proc_img_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN takes images in shape `(batch_size, h, w, channels)`, so reshape the images\n",
    "train_images = train_images.values.reshape(-1, IMG_X_SIZE, IMG_Y_SIZE, N_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(parent_directory+\"/data/train.csv\")\n",
    "Y_train_root = pd.get_dummies(train_labels['grapheme_root']).values\n",
    "Y_train_vowel = pd.get_dummies(train_labels['vowel_diacritic']).values\n",
    "Y_train_consonant = pd.get_dummies(train_labels['consonant_diacritic']).values\n",
    "del train_labels\n",
    "# print(f'Training images: {train_images.shape}')\n",
    "# print(f'Training labels root: {Y_train_root.shape}')\n",
    "# print(f'Training labels vowel: {Y_train_vowel.shape}')\n",
    "# print(f'Training labels consonants: {Y_train_consonant.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below this should take around 5 minutes\n",
    "x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant \\\n",
    "    = train_test_split(train_images, Y_train_root, Y_train_vowel, Y_train_consonant, test_size=0.3, random_state=666)\n",
    "del train_images\n",
    "x_val, x_test, y_val_root, y_test_root, y_val_vowel, y_test_vowel, y_val_consonant, y_test_consonant \\\n",
    "    = train_test_split(x_test, y_test_root, y_test_vowel, y_test_consonant, test_size=0.33, random_state=666)\n",
    "# print(f'x_train size: {x_train.shape}')\n",
    "# print(f'x_val size: {x_val.shape}')\n",
    "# print(f'x_test size: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n",
    "\n",
    "    def flow(self,\n",
    "             x,\n",
    "             y=None,\n",
    "             batch_size=32,\n",
    "             shuffle=True,\n",
    "             sample_weight=None,\n",
    "             seed=None,\n",
    "             save_to_dir=None,\n",
    "             save_prefix='',\n",
    "             save_format='png',\n",
    "             subset=None):\n",
    "\n",
    "        targets = None\n",
    "        target_lengths = {}\n",
    "        ordered_outputs = []\n",
    "        for output, target in y.items():\n",
    "            if targets is None:\n",
    "                targets = target\n",
    "            else:\n",
    "                targets = np.concatenate((targets, target), axis=1)\n",
    "            target_lengths[output] = target.shape[1]\n",
    "            ordered_outputs.append(output)\n",
    "\n",
    "\n",
    "        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n",
    "                                         shuffle=shuffle):\n",
    "            target_dict = {}\n",
    "            i = 0\n",
    "            for output in ordered_outputs:\n",
    "                target_length = target_lengths[output]\n",
    "                target_dict[output] = flowy[:, i: i + target_length]\n",
    "                i += target_length\n",
    "\n",
    "            yield flowx, target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data generator (should take two minutes)\n",
    "# Data augmentation for creating more training data\n",
    "datagen = MultiOutputDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.15, # Randomly zoom image \n",
    "    width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "# This will just calculate parameters required to augment the given data. This won't perform any augmentations\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Not going to use exponential anymore after realizing it sucks\n",
    "\"\"\"\n",
    "# need to edit these when we run the actual model and not doing hyperparameter tuning\n",
    "# initial_learning_rate = 0.01\n",
    "# decay_steps = 5 # this would be more like 10 or 20, since we'll be running more epochs\n",
    "# decay_rate = 0.1\n",
    "# learning_rate_exp_root = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#         initial_learning_rate = initial_learning_rate, decay_steps = decay_steps, decay_rate=decay_rate, name=\"lr_expD_root\")\n",
    "# learning_rate_exp_vowel = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#         initial_learning_rate = initial_learning_rate, decay_steps = decay_steps, decay_rate=decay_rate, name=\"lr_expD_vowel\")\n",
    "# learning_rate_exp_consonant = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#         initial_learning_rate = initial_learning_rate, decay_steps = decay_steps, decay_rate=decay_rate, name=\"lr_expD_consonant\")\n",
    "# LR_scheduler_exp_root = tf.keras.callbacks.LearningRateScheduler(learning_rate_exp_root)\n",
    "# LR_scheduler_exp_vowel = tf.keras.callbacks.LearningRateScheduler(learning_rate_exp_vowel)\n",
    "# LR_scheduler_exp_consonant = tf.keras.callbacks.LearningRateScheduler(learning_rate_exp_consonant)\n",
    "\n",
    "# def exponential_decay_fn(epoch):\n",
    "#     return 0.5 * 0.1 **(epoch / 3) # 1st var is initial lr, 2nd is decay_rate, 3rd is decay_steps, i think\n",
    "# lr_exp_root = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "# lr_exp_vowel = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "# lr_exp_consonant = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "learning_rate_reduction_root = ReduceLROnPlateau(monitor='dense_3_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "learning_rate_reduction_vowel = ReduceLROnPlateau(monitor='dense_4_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "learning_rate_reduction_consonant = ReduceLROnPlateau(monitor='dense_5_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1,\n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(activation, dropout_prob):\n",
    "    inputs = Input(shape = (IMG_X_SIZE, IMG_Y_SIZE, N_CHANNELS))\n",
    "    # first convolutional layer\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation, input_shape=(IMG_X_SIZE, IMG_Y_SIZE, N_CHANNELS))(inputs)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 2nd CL\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 3rd CL\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # 4th CL\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(5, 5), padding='SAME', activation=activation)(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    # dense layer\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(1024, activation=activation)(model)\n",
    "    model = Dropout(rate=dropout_prob)(model)\n",
    "    dense = Dense(512, activation=activation)(model)\n",
    "    # softmax layer\n",
    "    head_root = Dense(168, activation = 'softmax', name = \"dense_root\")(dense)\n",
    "    head_vowel = Dense(11, activation = 'softmax', name = \"dense_vowel\")(dense)\n",
    "    head_consonant = Dense(7, activation = 'softmax', name = \"dense_consonant\")(dense)\n",
    "    # output\n",
    "    model = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = [\"tanh\", \"relu\"]\n",
    "dropout_probs = [0.2, 0.4]\n",
    "optimizers = ['adam', 'nadam']\n",
    "# lr_schedulers = ['exp', 'power']\n",
    "batch_sizes = [256,128]\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Training model_8:\n",
      "\t Activation: relu\n",
      "\t Dropout Probability: 0.2\n",
      "\t Optimizer: adam\n",
      "\t Batch Size: 256\n",
      "Epoch 1/10\n",
      "549/549 [==============================] - 239s 435ms/step - loss: 6.3028 - dense_root_loss: 4.2207 - dense_vowel_loss: 1.1938 - dense_consonant_loss: 0.8883 - dense_root_accuracy: 0.0740 - dense_vowel_accuracy: 0.5936 - dense_consonant_accuracy: 0.6979 - val_loss: 3.5593 - val_dense_root_loss: 2.7114 - val_dense_vowel_loss: 0.4464 - val_dense_consonant_loss: 0.4012 - val_dense_root_accuracy: 0.2635 - val_dense_vowel_accuracy: 0.8496 - val_dense_consonant_accuracy: 0.8629\n",
      "Epoch 2/10\n",
      "  1/549 [..............................] - ETA: 48s - loss: 3.9388 - dense_root_loss: 2.9029 - dense_vowel_loss: 0.6232 - dense_consonant_loss: 0.4128 - dense_root_accuracy: 0.2045 - dense_vowel_accuracy: 0.8182 - dense_consonant_accuracy: 0.8636"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_3_accuracy` which is not available. Available metrics are: dense_root_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_loss,dense_consonant_accuracy,dense_vowel_accuracy,val_dense_root_accuracy,loss,lr,dense_vowel_loss,val_dense_consonant_loss,val_dense_root_loss,val_loss,val_dense_consonant_accuracy,val_dense_vowel_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_4_accuracy` which is not available. Available metrics are: dense_root_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_loss,dense_consonant_accuracy,dense_vowel_accuracy,val_dense_root_accuracy,loss,lr,dense_vowel_loss,val_dense_consonant_loss,val_dense_root_loss,val_loss,val_dense_consonant_accuracy,val_dense_vowel_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_5_accuracy` which is not available. Available metrics are: dense_root_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_loss,dense_consonant_accuracy,dense_vowel_accuracy,val_dense_root_accuracy,loss,lr,dense_vowel_loss,val_dense_consonant_loss,val_dense_root_loss,val_loss,val_dense_consonant_accuracy,val_dense_vowel_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 230s 419ms/step - loss: 3.0191 - dense_root_loss: 2.0293 - dense_vowel_loss: 0.5754 - dense_consonant_loss: 0.4145 - dense_root_accuracy: 0.4412 - dense_vowel_accuracy: 0.8124 - dense_consonant_accuracy: 0.8631 - val_loss: 1.3248 - val_dense_root_loss: 0.9098 - val_dense_vowel_loss: 0.2253 - val_dense_consonant_loss: 0.1895 - val_dense_root_accuracy: 0.7309 - val_dense_vowel_accuracy: 0.9287 - val_dense_consonant_accuracy: 0.9399\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 1.7405 - dense_root_loss: 1.0757 - dense_vowel_loss: 0.3892 - dense_consonant_loss: 0.2755 - dense_root_accuracy: 0.6951 - dense_vowel_accuracy: 0.8793 - dense_consonant_accuracy: 0.9113 - val_loss: 0.8914 - val_dense_root_loss: 0.5795 - val_dense_vowel_loss: 0.1661 - val_dense_consonant_loss: 0.1454 - val_dense_root_accuracy: 0.8357 - val_dense_vowel_accuracy: 0.9525 - val_dense_consonant_accuracy: 0.9548\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 1.3070 - dense_root_loss: 0.7772 - dense_vowel_loss: 0.3110 - dense_consonant_loss: 0.2188 - dense_root_accuracy: 0.7815 - dense_vowel_accuracy: 0.9061 - dense_consonant_accuracy: 0.9303 - val_loss: 0.6885 - val_dense_root_loss: 0.4466 - val_dense_vowel_loss: 0.1307 - val_dense_consonant_loss: 0.1110 - val_dense_root_accuracy: 0.8750 - val_dense_vowel_accuracy: 0.9647 - val_dense_consonant_accuracy: 0.9664\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 1.1219 - dense_root_loss: 0.6468 - dense_vowel_loss: 0.2792 - dense_consonant_loss: 0.1959 - dense_root_accuracy: 0.8174 - dense_vowel_accuracy: 0.9171 - dense_consonant_accuracy: 0.9383 - val_loss: 0.6234 - val_dense_root_loss: 0.3937 - val_dense_vowel_loss: 0.1261 - val_dense_consonant_loss: 0.1032 - val_dense_root_accuracy: 0.8909 - val_dense_vowel_accuracy: 0.9655 - val_dense_consonant_accuracy: 0.9687\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 0.9997 - dense_root_loss: 0.5703 - dense_vowel_loss: 0.2527 - dense_consonant_loss: 0.1767 - dense_root_accuracy: 0.8406 - dense_vowel_accuracy: 0.9250 - dense_consonant_accuracy: 0.9447 - val_loss: 0.5541 - val_dense_root_loss: 0.3513 - val_dense_vowel_loss: 0.1083 - val_dense_consonant_loss: 0.0943 - val_dense_root_accuracy: 0.9008 - val_dense_vowel_accuracy: 0.9724 - val_dense_consonant_accuracy: 0.9722\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 0.9136 - dense_root_loss: 0.5161 - dense_vowel_loss: 0.2321 - dense_consonant_loss: 0.1654 - dense_root_accuracy: 0.8541 - dense_vowel_accuracy: 0.9316 - dense_consonant_accuracy: 0.9486 - val_loss: 0.5635 - val_dense_root_loss: 0.3544 - val_dense_vowel_loss: 0.1068 - val_dense_consonant_loss: 0.1021 - val_dense_root_accuracy: 0.9023 - val_dense_vowel_accuracy: 0.9718 - val_dense_consonant_accuracy: 0.9683\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 0.8470 - dense_root_loss: 0.4717 - dense_vowel_loss: 0.2212 - dense_consonant_loss: 0.1541 - dense_root_accuracy: 0.8656 - dense_vowel_accuracy: 0.9347 - dense_consonant_accuracy: 0.9522 - val_loss: 0.5042 - val_dense_root_loss: 0.3225 - val_dense_vowel_loss: 0.0991 - val_dense_consonant_loss: 0.0826 - val_dense_root_accuracy: 0.9106 - val_dense_vowel_accuracy: 0.9744 - val_dense_consonant_accuracy: 0.9753\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 0.7983 - dense_root_loss: 0.4459 - dense_vowel_loss: 0.2062 - dense_consonant_loss: 0.1463 - dense_root_accuracy: 0.8735 - dense_vowel_accuracy: 0.9398 - dense_consonant_accuracy: 0.9546 - val_loss: 0.4812 - val_dense_root_loss: 0.2938 - val_dense_vowel_loss: 0.1052 - val_dense_consonant_loss: 0.0822 - val_dense_root_accuracy: 0.9205 - val_dense_vowel_accuracy: 0.9719 - val_dense_consonant_accuracy: 0.9763\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 230s 419ms/step - loss: 0.7595 - dense_root_loss: 0.4170 - dense_vowel_loss: 0.2007 - dense_consonant_loss: 0.1419 - dense_root_accuracy: 0.8825 - dense_vowel_accuracy: 0.9411 - dense_consonant_accuracy: 0.9563 - val_loss: 0.4708 - val_dense_root_loss: 0.2931 - val_dense_vowel_loss: 0.0962 - val_dense_consonant_loss: 0.0814 - val_dense_root_accuracy: 0.9204 - val_dense_vowel_accuracy: 0.9755 - val_dense_consonant_accuracy: 0.9768\n",
      "==========================================================================================\n",
      "Training model_12:\n",
      "\t Activation: relu\n",
      "\t Dropout Probability: 0.4\n",
      "\t Optimizer: adam\n",
      "\t Batch Size: 256\n",
      "Epoch 1/10\n",
      "549/549 [==============================] - 239s 435ms/step - loss: 6.8548 - dense_root_loss: 4.5421 - dense_vowel_loss: 1.3173 - dense_consonant_loss: 0.9953 - dense_root_accuracy: 0.0385 - dense_vowel_accuracy: 0.5447 - dense_consonant_accuracy: 0.6733 - val_loss: 5.3097 - val_dense_root_loss: 3.9747 - val_dense_vowel_loss: 0.7008 - val_dense_consonant_loss: 0.6337 - val_dense_root_accuracy: 0.0754 - val_dense_vowel_accuracy: 0.7627 - val_dense_consonant_accuracy: 0.7837\n",
      "Epoch 2/10\n",
      "  1/549 [..............................] - ETA: 48s - loss: 5.7625 - dense_root_loss: 4.1924 - dense_vowel_loss: 0.9676 - dense_consonant_loss: 0.6025 - dense_root_accuracy: 0.0682 - dense_vowel_accuracy: 0.6591 - dense_consonant_accuracy: 0.8409"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_3_accuracy` which is not available. Available metrics are: dense_root_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_loss,dense_consonant_accuracy,dense_vowel_accuracy,val_dense_root_accuracy,loss,lr,dense_vowel_loss,val_dense_consonant_loss,val_dense_root_loss,val_loss,val_dense_consonant_accuracy,val_dense_vowel_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_4_accuracy` which is not available. Available metrics are: dense_root_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_loss,dense_consonant_accuracy,dense_vowel_accuracy,val_dense_root_accuracy,loss,lr,dense_vowel_loss,val_dense_consonant_loss,val_dense_root_loss,val_loss,val_dense_consonant_accuracy,val_dense_vowel_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `dense_5_accuracy` which is not available. Available metrics are: dense_root_accuracy,val_dense_vowel_accuracy,dense_consonant_loss,dense_root_loss,dense_consonant_accuracy,dense_vowel_accuracy,val_dense_root_accuracy,loss,lr,dense_vowel_loss,val_dense_consonant_loss,val_dense_root_loss,val_loss,val_dense_consonant_accuracy,val_dense_vowel_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549/549 [==============================] - 231s 420ms/step - loss: 4.9951 - dense_root_loss: 3.6262 - dense_vowel_loss: 0.7732 - dense_consonant_loss: 0.5957 - dense_root_accuracy: 0.1209 - dense_vowel_accuracy: 0.7455 - dense_consonant_accuracy: 0.7976 - val_loss: 3.2427 - val_dense_root_loss: 2.5412 - val_dense_vowel_loss: 0.3783 - val_dense_consonant_loss: 0.3228 - val_dense_root_accuracy: 0.2736 - val_dense_vowel_accuracy: 0.8770 - val_dense_consonant_accuracy: 0.8933\n",
      "Epoch 3/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 3.1034 - dense_root_loss: 2.1490 - dense_vowel_loss: 0.5640 - dense_consonant_loss: 0.3905 - dense_root_accuracy: 0.3974 - dense_vowel_accuracy: 0.8220 - dense_consonant_accuracy: 0.8743 - val_loss: 1.5934 - val_dense_root_loss: 1.1329 - val_dense_vowel_loss: 0.2498 - val_dense_consonant_loss: 0.2104 - val_dense_root_accuracy: 0.6632 - val_dense_vowel_accuracy: 0.9275 - val_dense_consonant_accuracy: 0.9370\n",
      "Epoch 4/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 2.0432 - dense_root_loss: 1.3159 - dense_vowel_loss: 0.4268 - dense_consonant_loss: 0.3004 - dense_root_accuracy: 0.6256 - dense_vowel_accuracy: 0.8690 - dense_consonant_accuracy: 0.9050 - val_loss: 0.9428 - val_dense_root_loss: 0.6263 - val_dense_vowel_loss: 0.1709 - val_dense_consonant_loss: 0.1456 - val_dense_root_accuracy: 0.8159 - val_dense_vowel_accuracy: 0.9521 - val_dense_consonant_accuracy: 0.9561\n",
      "Epoch 5/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 1.5558 - dense_root_loss: 0.9544 - dense_vowel_loss: 0.3528 - dense_consonant_loss: 0.2486 - dense_root_accuracy: 0.7323 - dense_vowel_accuracy: 0.8934 - dense_consonant_accuracy: 0.9222 - val_loss: 0.7547 - val_dense_root_loss: 0.4973 - val_dense_vowel_loss: 0.1314 - val_dense_consonant_loss: 0.1257 - val_dense_root_accuracy: 0.8580 - val_dense_vowel_accuracy: 0.9644 - val_dense_consonant_accuracy: 0.9612\n",
      "Epoch 6/10\n",
      "549/549 [==============================] - 230s 420ms/step - loss: 1.3093 - dense_root_loss: 0.7792 - dense_vowel_loss: 0.3114 - dense_consonant_loss: 0.2187 - dense_root_accuracy: 0.7826 - dense_vowel_accuracy: 0.9080 - dense_consonant_accuracy: 0.9323 - val_loss: 0.6222 - val_dense_root_loss: 0.3988 - val_dense_vowel_loss: 0.1152 - val_dense_consonant_loss: 0.1080 - val_dense_root_accuracy: 0.8873 - val_dense_vowel_accuracy: 0.9687 - val_dense_consonant_accuracy: 0.9682\n",
      "Epoch 7/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 1.1523 - dense_root_loss: 0.6722 - dense_vowel_loss: 0.2818 - dense_consonant_loss: 0.1982 - dense_root_accuracy: 0.8120 - dense_vowel_accuracy: 0.9171 - dense_consonant_accuracy: 0.9391 - val_loss: 0.5811 - val_dense_root_loss: 0.3671 - val_dense_vowel_loss: 0.1113 - val_dense_consonant_loss: 0.1026 - val_dense_root_accuracy: 0.8967 - val_dense_vowel_accuracy: 0.9714 - val_dense_consonant_accuracy: 0.9688\n",
      "Epoch 8/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 1.0466 - dense_root_loss: 0.6026 - dense_vowel_loss: 0.2608 - dense_consonant_loss: 0.1833 - dense_root_accuracy: 0.8307 - dense_vowel_accuracy: 0.9242 - dense_consonant_accuracy: 0.9441 - val_loss: 0.5580 - val_dense_root_loss: 0.3552 - val_dense_vowel_loss: 0.1029 - val_dense_consonant_loss: 0.0997 - val_dense_root_accuracy: 0.9021 - val_dense_vowel_accuracy: 0.9740 - val_dense_consonant_accuracy: 0.9708\n",
      "Epoch 9/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 0.9697 - dense_root_loss: 0.5542 - dense_vowel_loss: 0.2427 - dense_consonant_loss: 0.1728 - dense_root_accuracy: 0.8460 - dense_vowel_accuracy: 0.9285 - dense_consonant_accuracy: 0.9472 - val_loss: 0.5310 - val_dense_root_loss: 0.3323 - val_dense_vowel_loss: 0.1030 - val_dense_consonant_loss: 0.0954 - val_dense_root_accuracy: 0.9083 - val_dense_vowel_accuracy: 0.9729 - val_dense_consonant_accuracy: 0.9731\n",
      "Epoch 10/10\n",
      "549/549 [==============================] - 231s 420ms/step - loss: 0.9240 - dense_root_loss: 0.5202 - dense_vowel_loss: 0.2382 - dense_consonant_loss: 0.1655 - dense_root_accuracy: 0.8545 - dense_vowel_accuracy: 0.9311 - dense_consonant_accuracy: 0.9492 - val_loss: 0.4801 - val_dense_root_loss: 0.3000 - val_dense_vowel_loss: 0.0924 - val_dense_consonant_loss: 0.0876 - val_dense_root_accuracy: 0.9164 - val_dense_vowel_accuracy: 0.9759 - val_dense_consonant_accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "# TUNE THE MODEL\n",
    "if not os.path.exists(parent_directory+\"/models\"):\n",
    "    os.makedirs(parent_directory+\"/models\")\n",
    "histories = {}\n",
    "counter = 0 \n",
    "for activation in activations:\n",
    "    for dropout_prob in dropout_probs:\n",
    "        for optimizer in optimizers:\n",
    "            for batch_size in batch_sizes:\n",
    "    #             # MAKE SURE YOU EDIT THIS OUT LATER BUT THIS IS JUST TO SKIP MODEL 0 CUZ WE ALREADY TRIED IT\n",
    "                if not (counter==8 or counter==12):\n",
    "                    counter += 1\n",
    "                    continue\n",
    "                print(\"==========================================================================================\")\n",
    "                print(\"Training model_\"+str(counter) +\":\")\n",
    "                print(\"\\t Activation: \" + activation)\n",
    "                print(\"\\t Dropout Probability: \" + str(dropout_prob))\n",
    "                print(\"\\t Optimizer: \" + optimizer)\n",
    "                print(\"\\t Batch Size: \" + str(batch_size))\n",
    "                model = build_model(activation, dropout_prob)\n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                callbacks=[learning_rate_reduction_root, learning_rate_reduction_vowel, learning_rate_reduction_consonant]\n",
    "                history = model.fit_generator(\n",
    "                        datagen.flow(\n",
    "                            x_train, {'dense_root': y_train_root, 'dense_vowel': y_train_vowel, 'dense_consonant': y_train_consonant}, \n",
    "                            batch_size=batch_size),\n",
    "                        epochs = epochs, validation_data = (x_val, [y_val_root, y_val_vowel, y_val_consonant]), \n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size, \n",
    "                        callbacks=callbacks\n",
    "                    )\n",
    "                # need to change values of history to float64s or floats, float32 is not json serializable\n",
    "                for key in history.history.keys():\n",
    "                    history.history[key] = [np.float64(val) for val in history.history[key]]\n",
    "                # add history to histories\n",
    "                histories[\"model_\" + str(counter)] = (activation, dropout_prob, optimizer, batch_size, history.history)\n",
    "                # save histories as json file\n",
    "                with open(parent_directory+\"/models/model_\" + str(counter)+\".json\", \"w\") as fp:\n",
    "                    json.dump(history.history, fp, sort_keys = True, indent = 4)\n",
    "                counter += 1\n",
    "                del model\n",
    "                del history\n",
    "with open(parent_directory+\"/models/histories.json\", \"w\") as fp:\n",
    "    json.dump(histories, fp, sort_keys = True, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(parent_directory+\"/models/histories.json\", \"w\") as fp:\n",
    "    json.dump(histories, fp, sort_keys = True, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_0': ('tanh',\n",
       "  0.2,\n",
       "  'adam',\n",
       "  'exp',\n",
       "  {'dense_consonant_accuracy': [0.7153489589691162,\n",
       "    0.830986499786377,\n",
       "    0.8645355105400085,\n",
       "    0.8792933821678162,\n",
       "    0.8850440382957458,\n",
       "    0.8889134526252747,\n",
       "    0.8886640071868896,\n",
       "    0.8907376527786255,\n",
       "    0.8902531266212463,\n",
       "    0.8910797238349915],\n",
       "   'dense_consonant_loss': [0.8337407112121582,\n",
       "    0.5041878819465637,\n",
       "    0.410670667886734,\n",
       "    0.3695290684700012,\n",
       "    0.34943297505378723,\n",
       "    0.34197208285331726,\n",
       "    0.337189257144928,\n",
       "    0.33394184708595276,\n",
       "    0.33507055044174194,\n",
       "    0.3337043225765228],\n",
       "   'dense_root_accuracy': [0.08045167475938797,\n",
       "    0.3248724341392517,\n",
       "    0.4970569908618927,\n",
       "    0.5793760418891907,\n",
       "    0.6145996451377869,\n",
       "    0.6340250372886658,\n",
       "    0.6380725502967834,\n",
       "    0.648861289024353,\n",
       "    0.6514408588409424,\n",
       "    0.6503862142562866],\n",
       "   'dense_root_loss': [4.170259475708008,\n",
       "    2.5790419578552246,\n",
       "    1.8359626531600952,\n",
       "    1.528229832649231,\n",
       "    1.39825439453125,\n",
       "    1.3231263160705566,\n",
       "    1.3042891025543213,\n",
       "    1.2676481008529663,\n",
       "    1.2556109428405762,\n",
       "    1.2657874822616577],\n",
       "   'dense_vowel_accuracy': [0.6243026852607727,\n",
       "    0.7825086116790771,\n",
       "    0.8223356008529663,\n",
       "    0.8457515239715576,\n",
       "    0.8535187840461731,\n",
       "    0.8561625480651855,\n",
       "    0.8574166893959045,\n",
       "    0.8594689965248108,\n",
       "    0.8620628118515015,\n",
       "    0.8589202761650085],\n",
       "   'dense_vowel_loss': [1.1010299921035767,\n",
       "    0.6647822856903076,\n",
       "    0.5519440174102783,\n",
       "    0.4854833483695984,\n",
       "    0.460762083530426,\n",
       "    0.4489850103855133,\n",
       "    0.4465622901916504,\n",
       "    0.4434627890586853,\n",
       "    0.43570005893707275,\n",
       "    0.4455600082874298],\n",
       "   'loss': [6.1050280465020075,\n",
       "    3.7464013426006817,\n",
       "    2.7972903465445187,\n",
       "    2.3811351258864213,\n",
       "    2.2088770202610024,\n",
       "    2.1144701957437597,\n",
       "    2.086568362553226,\n",
       "    2.0446365771222825,\n",
       "    2.0265459703161586,\n",
       "    2.044966940284098],\n",
       "   'lr': [0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513],\n",
       "   'val_dense_consonant_accuracy': [0.8487663269042969,\n",
       "    0.9051228761672974,\n",
       "    0.9190695881843567,\n",
       "    0.9246432781219482,\n",
       "    0.9329419136047363,\n",
       "    0.9312326312065125,\n",
       "    0.9362366199493408,\n",
       "    0.9355430006980896,\n",
       "    0.9318767189979553,\n",
       "    0.9359889030456543],\n",
       "   'val_dense_consonant_loss': [0.4412265121936798,\n",
       "    0.2957174777984619,\n",
       "    0.2500893771648407,\n",
       "    0.229720339179039,\n",
       "    0.21244363486766815,\n",
       "    0.21328191459178925,\n",
       "    0.20331868529319763,\n",
       "    0.20585395395755768,\n",
       "    0.21128956973552704,\n",
       "    0.20260491967201233],\n",
       "   'val_dense_root_accuracy': [0.23062822222709656,\n",
       "    0.5351516008377075,\n",
       "    0.6606222987174988,\n",
       "    0.7138079404830933,\n",
       "    0.7294144034385681,\n",
       "    0.7429647445678711,\n",
       "    0.7485632300376892,\n",
       "    0.7601070404052734,\n",
       "    0.7560443878173828,\n",
       "    0.7628071904182434],\n",
       "   'val_dense_root_loss': [2.9886224269866943,\n",
       "    1.636429786682129,\n",
       "    1.1969642639160156,\n",
       "    1.022706389427185,\n",
       "    0.9661627411842346,\n",
       "    0.9072456955909729,\n",
       "    0.8881219029426575,\n",
       "    0.8599123358726501,\n",
       "    0.8690063953399658,\n",
       "    0.8313584923744202],\n",
       "   'val_dense_vowel_accuracy': [0.8262980580329895,\n",
       "    0.8921918272972107,\n",
       "    0.9073275923728943,\n",
       "    0.9225128889083862,\n",
       "    0.9261048436164856,\n",
       "    0.9340319037437439,\n",
       "    0.9331896305084229,\n",
       "    0.9313812851905823,\n",
       "    0.932174026966095,\n",
       "    0.9329419136047363],\n",
       "   'val_dense_vowel_loss': [0.539808452129364,\n",
       "    0.347901314496994,\n",
       "    0.30104631185531616,\n",
       "    0.2552106976509094,\n",
       "    0.24572929739952087,\n",
       "    0.22504085302352905,\n",
       "    0.22552786767482758,\n",
       "    0.2293962687253952,\n",
       "    0.22647693753242493,\n",
       "    0.22533859312534332],\n",
       "   'val_loss': [3.9698780708449064,\n",
       "    2.2804799870843695,\n",
       "    1.748372361010802,\n",
       "    1.508048933789317,\n",
       "    1.4244906141603932,\n",
       "    1.345772949845083,\n",
       "    1.317107689319222,\n",
       "    1.2955239913409728,\n",
       "    1.3070747534811993,\n",
       "    1.2595766168523297]}),\n",
       " 'model_1': ('tanh',\n",
       "  0.2,\n",
       "  'adam',\n",
       "  'exp',\n",
       "  {'dense_consonant_accuracy': [0.7090804576873779,\n",
       "    0.8005339503288269,\n",
       "    0.8271109461784363,\n",
       "    0.8352840542793274,\n",
       "    0.8390360474586487,\n",
       "    0.8392425179481506,\n",
       "    0.8361384272575378,\n",
       "    0.8338673114776611,\n",
       "    0.8330414295196533,\n",
       "    0.8301580548286438],\n",
       "   'dense_consonant_loss': [0.8482224345207214,\n",
       "    0.5830042362213135,\n",
       "    0.5128202438354492,\n",
       "    0.49098557233810425,\n",
       "    0.48068520426750183,\n",
       "    0.4807240068912506,\n",
       "    0.488582581281662,\n",
       "    0.48957398533821106,\n",
       "    0.4948359727859497,\n",
       "    0.5011873245239258],\n",
       "   'dense_root_accuracy': [0.0680854395031929,\n",
       "    0.23428022861480713,\n",
       "    0.3507831394672394,\n",
       "    0.40301865339279175,\n",
       "    0.4265128970146179,\n",
       "    0.43646588921546936,\n",
       "    0.43598178029060364,\n",
       "    0.43525558710098267,\n",
       "    0.42600739002227783,\n",
       "    0.4234159290790558],\n",
       "   'dense_root_loss': [4.290377140045166,\n",
       "    3.0460422039031982,\n",
       "    2.4683563709259033,\n",
       "    2.2348110675811768,\n",
       "    2.146637439727783,\n",
       "    2.1038730144500732,\n",
       "    2.1143057346343994,\n",
       "    2.121692419052124,\n",
       "    2.172473669052124,\n",
       "    2.177278995513916],\n",
       "   'dense_vowel_accuracy': [0.6030922532081604,\n",
       "    0.7432436347007751,\n",
       "    0.7722696661949158,\n",
       "    0.7865584492683411,\n",
       "    0.782863438129425,\n",
       "    0.7898262739181519,\n",
       "    0.7835255861282349,\n",
       "    0.7842588424682617,\n",
       "    0.773358941078186,\n",
       "    0.7733305096626282],\n",
       "   'dense_vowel_loss': [1.1601922512054443,\n",
       "    0.7739391326904297,\n",
       "    0.6917765140533447,\n",
       "    0.6528014540672302,\n",
       "    0.6584819555282593,\n",
       "    0.6418158411979675,\n",
       "    0.6550992727279663,\n",
       "    0.657509446144104,\n",
       "    0.6851291060447693,\n",
       "    0.6836275458335876],\n",
       "   'loss': [6.298793591653932,\n",
       "    4.402907525225105,\n",
       "    3.6724705827010418,\n",
       "    3.3786626958242767,\n",
       "    3.2857214298272734,\n",
       "    3.226847185403486,\n",
       "    3.2577419744874785,\n",
       "    3.268934523018782,\n",
       "    3.3526267067991937,\n",
       "    3.3619518240513533],\n",
       "   'lr': [0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513],\n",
       "   'val_dense_consonant_accuracy': [0.8364298343658447,\n",
       "    0.8727704882621765,\n",
       "    0.8934552073478699,\n",
       "    0.8909037113189697,\n",
       "    0.8897889256477356,\n",
       "    0.8906311988830566,\n",
       "    0.892315685749054,\n",
       "    0.8968489766120911,\n",
       "    0.8961306214332581,\n",
       "    0.8854290246963501],\n",
       "   'val_dense_consonant_loss': [0.48772817850112915,\n",
       "    0.382463663816452,\n",
       "    0.32585570216178894,\n",
       "    0.3312280476093292,\n",
       "    0.33406737446784973,\n",
       "    0.3306327164173126,\n",
       "    0.3227328956127167,\n",
       "    0.3099788427352905,\n",
       "    0.31464046239852905,\n",
       "    0.3478999137878418],\n",
       "   'val_dense_root_accuracy': [0.18888723850250244,\n",
       "    0.3764120042324066,\n",
       "    0.5029973983764648,\n",
       "    0.5383719801902771,\n",
       "    0.5536563396453857,\n",
       "    0.5500396490097046,\n",
       "    0.5360929369926453,\n",
       "    0.5643826723098755,\n",
       "    0.5596759915351868,\n",
       "    0.5287851691246033],\n",
       "   'val_dense_root_loss': [3.2329599857330322,\n",
       "    2.273505210876465,\n",
       "    1.7730743885040283,\n",
       "    1.6441220045089722,\n",
       "    1.594468116760254,\n",
       "    1.5928789377212524,\n",
       "    1.6512198448181152,\n",
       "    1.5545397996902466,\n",
       "    1.564191460609436,\n",
       "    1.7017196416854858],\n",
       "   'val_dense_vowel_accuracy': [0.8168103694915771,\n",
       "    0.8525317311286926,\n",
       "    0.8751981854438782,\n",
       "    0.8745293021202087,\n",
       "    0.8759908676147461,\n",
       "    0.8779973983764648,\n",
       "    0.8796323537826538,\n",
       "    0.8806480169296265,\n",
       "    0.8841904401779175,\n",
       "    0.8714823722839355],\n",
       "   'val_dense_vowel_loss': [0.5677709579467773,\n",
       "    0.46157780289649963,\n",
       "    0.39868202805519104,\n",
       "    0.3925923705101013,\n",
       "    0.3993154764175415,\n",
       "    0.37874823808670044,\n",
       "    0.37821894884109497,\n",
       "    0.3871045708656311,\n",
       "    0.3788502514362335,\n",
       "    0.4149036109447479],\n",
       "   'val_loss': [4.28889195766895,\n",
       "    3.117487016765551,\n",
       "    2.4973107050488594,\n",
       "    2.368364382961937,\n",
       "    2.3272355882317313,\n",
       "    2.3015145193335087,\n",
       "    2.351386879154769,\n",
       "    2.251645072981615,\n",
       "    2.2570036171071357,\n",
       "    2.463969171023586]}),\n",
       " 'model_2': ('tanh',\n",
       "  0.2,\n",
       "  'nadam',\n",
       "  'exp',\n",
       "  {'dense_consonant_accuracy': [0.6386469602584839,\n",
       "    0.7119972705841064,\n",
       "    0.7446840405464172,\n",
       "    0.62168288230896,\n",
       "    0.624590277671814,\n",
       "    0.6251175999641418,\n",
       "    0.6251246929168701,\n",
       "    0.6249322891235352,\n",
       "    0.6245261430740356,\n",
       "    0.6252672076225281],\n",
       "   'dense_consonant_loss': [1.1093608140945435,\n",
       "    0.8235564827919006,\n",
       "    0.7246729731559753,\n",
       "    1.255475401878357,\n",
       "    1.219467282295227,\n",
       "    1.2157436609268188,\n",
       "    1.214453935623169,\n",
       "    1.2144733667373657,\n",
       "    1.2129855155944824,\n",
       "    1.2095307111740112],\n",
       "   'dense_root_accuracy': [0.0368923619389534,\n",
       "    0.1035686805844307,\n",
       "    0.16641250252723694,\n",
       "    0.025425419211387634,\n",
       "    0.023330388590693474,\n",
       "    0.024000227451324463,\n",
       "    0.02394322119653225,\n",
       "    0.02427813969552517,\n",
       "    0.02481258660554886,\n",
       "    0.024727076292037964],\n",
       "   'dense_root_loss': [4.613177299499512,\n",
       "    3.928417921066284,\n",
       "    3.462066173553467,\n",
       "    4.814720153808594,\n",
       "    4.812802314758301,\n",
       "    4.804044246673584,\n",
       "    4.803223609924316,\n",
       "    4.793560981750488,\n",
       "    4.795528888702393,\n",
       "    4.79146671295166],\n",
       "   'dense_vowel_accuracy': [0.42001792788505554,\n",
       "    0.6235356330871582,\n",
       "    0.6821109652519226,\n",
       "    0.19547216594219208,\n",
       "    0.1904127299785614,\n",
       "    0.1922227293252945,\n",
       "    0.19120371341705322,\n",
       "    0.19252201914787292,\n",
       "    0.19310635328292847,\n",
       "    0.19307072460651398],\n",
       "   'dense_vowel_loss': [1.6369445323944092,\n",
       "    1.0972322225570679,\n",
       "    0.934501051902771,\n",
       "    2.1920435428619385,\n",
       "    2.164186477661133,\n",
       "    2.159116268157959,\n",
       "    2.159508466720581,\n",
       "    2.1556646823883057,\n",
       "    2.153597116470337,\n",
       "    2.1531505584716797],\n",
       "   'loss': [7.359482928486252,\n",
       "    5.848872876502332,\n",
       "    5.120789958233063,\n",
       "    8.267190512836658,\n",
       "    8.196236965182814,\n",
       "    8.178773634647747,\n",
       "    8.17694649904167,\n",
       "    8.16385604170224,\n",
       "    8.162139196330362,\n",
       "    8.15414543098576],\n",
       "   'lr': [0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026],\n",
       "   'val_dense_consonant_accuracy': [0.6870788931846619,\n",
       "    0.7624108195304871,\n",
       "    0.8070749044418335,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149],\n",
       "   'val_dense_consonant_loss': [0.8412973880767822,\n",
       "    0.6589599847793579,\n",
       "    0.544544517993927,\n",
       "    1.212827444076538,\n",
       "    1.2173157930374146,\n",
       "    1.2238335609436035,\n",
       "    1.2326678037643433,\n",
       "    1.2308703660964966,\n",
       "    1.2132453918457031,\n",
       "    1.2108304500579834],\n",
       "   'val_dense_root_accuracy': [0.07721462845802307,\n",
       "    0.16874752938747406,\n",
       "    0.2461850941181183,\n",
       "    0.027174990624189377,\n",
       "    0.02786860801279545,\n",
       "    0.025069361552596092,\n",
       "    0.02231965959072113,\n",
       "    0.027174990624189377,\n",
       "    0.017464328557252884,\n",
       "    0.02231965959072113],\n",
       "   'val_dense_root_loss': [4.114812850952148,\n",
       "    3.3503711223602295,\n",
       "    2.9357240200042725,\n",
       "    4.812905311584473,\n",
       "    4.76628303527832,\n",
       "    4.757361888885498,\n",
       "    4.774273872375488,\n",
       "    4.788874626159668,\n",
       "    4.806513786315918,\n",
       "    4.772154331207275],\n",
       "   'val_dense_vowel_accuracy': [0.6854439377784729,\n",
       "    0.75022292137146,\n",
       "    0.7966210842132568,\n",
       "    0.20446889102458954,\n",
       "    0.18390804529190063,\n",
       "    0.20446889102458954,\n",
       "    0.18390804529190063,\n",
       "    0.18390804529190063,\n",
       "    0.18390804529190063,\n",
       "    0.12869104743003845],\n",
       "   'val_dense_vowel_loss': [0.8979244232177734,\n",
       "    0.7300342321395874,\n",
       "    0.6152505278587341,\n",
       "    2.171931028366089,\n",
       "    2.1497926712036133,\n",
       "    2.149296522140503,\n",
       "    2.1726303100585938,\n",
       "    2.199838161468506,\n",
       "    2.164264678955078,\n",
       "    2.175640344619751],\n",
       "   'val_loss': [5.854254639436931,\n",
       "    4.739547931151026,\n",
       "    4.096032792407749,\n",
       "    8.197775807117972,\n",
       "    8.133577982206644,\n",
       "    8.130616385739236,\n",
       "    8.179769855428205,\n",
       "    8.219748488315457,\n",
       "    8.184191869734962,\n",
       "    8.158621960389345]}),\n",
       " 'model_3': ('tanh',\n",
       "  0.2,\n",
       "  'nadam',\n",
       "  'exp',\n",
       "  {'dense_consonant_accuracy': [0.6368610262870789,\n",
       "    0.6689804792404175,\n",
       "    0.6399829387664795,\n",
       "    0.6249038577079773,\n",
       "    0.624896764755249,\n",
       "    0.6249537467956543,\n",
       "    0.6248682737350464,\n",
       "    0.6250676512718201,\n",
       "    0.6249323487281799,\n",
       "    0.6252028942108154],\n",
       "   'dense_consonant_loss': [1.0841201543807983,\n",
       "    0.9503790736198425,\n",
       "    1.1431831121444702,\n",
       "    1.2195652723312378,\n",
       "    1.2172669172286987,\n",
       "    1.2149431705474854,\n",
       "    1.213241696357727,\n",
       "    1.2117148637771606,\n",
       "    1.2115821838378906,\n",
       "    1.2108975648880005],\n",
       "   'dense_root_accuracy': [0.03864981606602669,\n",
       "    0.07310266047716141,\n",
       "    0.04020361602306366,\n",
       "    0.022554464638233185,\n",
       "    0.024170583114027977,\n",
       "    0.022853480651974678,\n",
       "    0.023458635434508324,\n",
       "    0.023850206285715103,\n",
       "    0.0246262289583683,\n",
       "    0.0240851491689682],\n",
       "   'dense_root_loss': [4.606263160705566,\n",
       "    4.230986595153809,\n",
       "    4.6494903564453125,\n",
       "    4.848083972930908,\n",
       "    4.842711448669434,\n",
       "    4.8378214836120605,\n",
       "    4.835970401763916,\n",
       "    4.83688497543335,\n",
       "    4.8367390632629395,\n",
       "    4.8377885818481445],\n",
       "   'dense_vowel_accuracy': [0.4584329426288605,\n",
       "    0.5459205508232117,\n",
       "    0.30104655027389526,\n",
       "    0.18840239942073822,\n",
       "    0.18891499936580658,\n",
       "    0.1895771026611328,\n",
       "    0.19337889552116394,\n",
       "    0.19251032173633575,\n",
       "    0.19272390007972717,\n",
       "    0.19368503987789154],\n",
       "   'dense_vowel_loss': [1.5273164510726929,\n",
       "    1.2917734384536743,\n",
       "    1.906569480895996,\n",
       "    2.167330265045166,\n",
       "    2.162139415740967,\n",
       "    2.1591644287109375,\n",
       "    2.156231641769409,\n",
       "    2.155449390411377,\n",
       "    2.1547598838806152,\n",
       "    2.1535544395446777],\n",
       "   'loss': [7.2176994369763925,\n",
       "    6.472977868549576,\n",
       "    7.700055640670253,\n",
       "    8.235119321267183,\n",
       "    8.222207578240544,\n",
       "    8.211836194442103,\n",
       "    8.205529353578902,\n",
       "    8.204032714927399,\n",
       "    8.203207185569523,\n",
       "    8.202208508118492],\n",
       "   'lr': [0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026,\n",
       "    0.0020000000949949026],\n",
       "   'val_dense_consonant_accuracy': [0.6815051436424255,\n",
       "    0.7005549073219299,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149,\n",
       "    0.6201198697090149],\n",
       "   'val_dense_consonant_loss': [0.899556040763855,\n",
       "    0.8367127180099487,\n",
       "    1.2156497240066528,\n",
       "    1.2164512872695923,\n",
       "    1.2202110290527344,\n",
       "    1.2051836252212524,\n",
       "    1.221177577972412,\n",
       "    1.219954490661621,\n",
       "    1.240153193473816,\n",
       "    1.2108579874038696],\n",
       "   'val_dense_root_accuracy': [0.06975822150707245,\n",
       "    0.08291220664978027,\n",
       "    0.027199761942029,\n",
       "    0.025069361552596092,\n",
       "    0.022121481597423553,\n",
       "    0.022121481597423553,\n",
       "    0.025069361552596092,\n",
       "    0.02992469258606434,\n",
       "    0.027199761942029,\n",
       "    0.017464328557252884],\n",
       "   'val_dense_root_loss': [4.162173271179199,\n",
       "    3.9812722206115723,\n",
       "    4.851775169372559,\n",
       "    4.812920093536377,\n",
       "    4.8135199546813965,\n",
       "    4.83963680267334,\n",
       "    4.798985481262207,\n",
       "    4.835487365722656,\n",
       "    4.793559551239014,\n",
       "    4.825561046600342],\n",
       "   'val_dense_vowel_accuracy': [0.656708300113678,\n",
       "    0.6461058259010315,\n",
       "    0.20446889102458954,\n",
       "    0.18390804529190063,\n",
       "    0.18390804529190063,\n",
       "    0.20446889102458954,\n",
       "    0.20446889102458954,\n",
       "    0.18390804529190063,\n",
       "    0.18390804529190063,\n",
       "    0.20446889102458954],\n",
       "   'val_dense_vowel_loss': [0.9849834442138672,\n",
       "    0.9886292219161987,\n",
       "    2.1879923343658447,\n",
       "    2.1684694290161133,\n",
       "    2.17213773727417,\n",
       "    2.1470179557800293,\n",
       "    2.164522409439087,\n",
       "    2.1729063987731934,\n",
       "    2.179835796356201,\n",
       "    2.177403211593628],\n",
       "   'val_loss': [6.046547370159196,\n",
       "    5.8065638186862625,\n",
       "    8.2560338830362,\n",
       "    8.19818453272798,\n",
       "    8.206153001002834,\n",
       "    8.191980067104561,\n",
       "    8.185025183775574,\n",
       "    8.228697670956619,\n",
       "    8.213778530185865,\n",
       "    8.214326439516157]}),\n",
       " 'model_4': ('tanh',\n",
       "  0.4,\n",
       "  'adam',\n",
       "  'exp',\n",
       "  {'dense_consonant_accuracy': [0.6691925525665283,\n",
       "    0.7749907374382019,\n",
       "    0.8200481534004211,\n",
       "    0.8383761644363403,\n",
       "    0.8472978472709656,\n",
       "    0.8508322834968567,\n",
       "    0.8538323640823364,\n",
       "    0.8569464087486267,\n",
       "    0.8562195301055908,\n",
       "    0.8560556173324585],\n",
       "   'dense_consonant_loss': [0.9803644418716431,\n",
       "    0.6439511179924011,\n",
       "    0.533479630947113,\n",
       "    0.48212048411369324,\n",
       "    0.45836225152015686,\n",
       "    0.4484354853630066,\n",
       "    0.4400292634963989,\n",
       "    0.4305652678012848,\n",
       "    0.4291445016860962,\n",
       "    0.4325959086418152],\n",
       "   'dense_root_accuracy': [0.04082707315683365,\n",
       "    0.14762134850025177,\n",
       "    0.2953495979309082,\n",
       "    0.38916996121406555,\n",
       "    0.4417809247970581,\n",
       "    0.46739161014556885,\n",
       "    0.49126356840133667,\n",
       "    0.5036770105361938,\n",
       "    0.5155203342437744,\n",
       "    0.509833812713623],\n",
       "   'dense_root_loss': [4.571709632873535,\n",
       "    3.558694362640381,\n",
       "    2.6960859298706055,\n",
       "    2.273087739944458,\n",
       "    2.0582327842712402,\n",
       "    1.9583179950714111,\n",
       "    1.8673300743103027,\n",
       "    1.8188612461090088,\n",
       "    1.7820773124694824,\n",
       "    1.7987054586410522],\n",
       "   'dense_vowel_accuracy': [0.5245261192321777,\n",
       "    0.7334820032119751,\n",
       "    0.7753185033798218,\n",
       "    0.7956275343894958,\n",
       "    0.8074922561645508,\n",
       "    0.8083829879760742,\n",
       "    0.8117393255233765,\n",
       "    0.8145469427108765,\n",
       "    0.8163070678710938,\n",
       "    0.8163782954216003],\n",
       "   'dense_vowel_loss': [1.365631341934204,\n",
       "    0.8096767663955688,\n",
       "    0.6909680366516113,\n",
       "    0.627878725528717,\n",
       "    0.5956601500511169,\n",
       "    0.5916104912757874,\n",
       "    0.5774439573287964,\n",
       "    0.571513295173645,\n",
       "    0.566848874092102,\n",
       "    0.5690808892250061],\n",
       "   'loss': [6.917705633166927,\n",
       "    5.01089561433751,\n",
       "    3.92042490380814,\n",
       "    3.3825474071029693,\n",
       "    3.112502285560432,\n",
       "    2.997170496064411,\n",
       "    2.884883088403365,\n",
       "    2.821095350323295,\n",
       "    2.7783760707041245,\n",
       "    2.8007468837793708],\n",
       "   'lr': [0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513],\n",
       "   'val_dense_consonant_accuracy': [0.7800980806350708,\n",
       "    0.8654131889343262,\n",
       "    0.892315685749054,\n",
       "    0.9006391167640686,\n",
       "    0.9036861062049866,\n",
       "    0.9119599461555481,\n",
       "    0.9155271649360657,\n",
       "    0.9155271649360657,\n",
       "    0.9129756093025208,\n",
       "    0.9164437055587769],\n",
       "   'val_dense_consonant_loss': [0.5775768160820007,\n",
       "    0.39295676350593567,\n",
       "    0.33212265372276306,\n",
       "    0.30501800775527954,\n",
       "    0.2953811287879944,\n",
       "    0.2683678865432739,\n",
       "    0.2620307207107544,\n",
       "    0.25777456164360046,\n",
       "    0.26240038871765137,\n",
       "    0.2580454647541046],\n",
       "   'val_dense_root_accuracy': [0.0951743945479393,\n",
       "    0.3151753842830658,\n",
       "    0.4703477919101715,\n",
       "    0.5592300891876221,\n",
       "    0.587049126625061,\n",
       "    0.6214823722839355,\n",
       "    0.6475425958633423,\n",
       "    0.6613406538963318,\n",
       "    0.660250723361969,\n",
       "    0.6606222987174988],\n",
       "   'val_dense_root_loss': [3.9248926639556885,\n",
       "    2.547297239303589,\n",
       "    1.880446195602417,\n",
       "    1.5572359561920166,\n",
       "    1.4329555034637451,\n",
       "    1.3172160387039185,\n",
       "    1.2277244329452515,\n",
       "    1.2022557258605957,\n",
       "    1.1852765083312988,\n",
       "    1.192442536354065],\n",
       "   'val_dense_vowel_accuracy': [0.8102457523345947,\n",
       "    0.863084614276886,\n",
       "    0.8824564218521118,\n",
       "    0.8969480991363525,\n",
       "    0.8980380296707153,\n",
       "    0.9067330360412598,\n",
       "    0.9102259278297424,\n",
       "    0.9066091775894165,\n",
       "    0.9124306440353394,\n",
       "    0.9111672639846802],\n",
       "   'val_dense_vowel_loss': [0.5755183696746826,\n",
       "    0.44098034501075745,\n",
       "    0.37686893343925476,\n",
       "    0.3396792709827423,\n",
       "    0.3214971423149109,\n",
       "    0.31292057037353516,\n",
       "    0.29610347747802734,\n",
       "    0.30362018942832947,\n",
       "    0.29267287254333496,\n",
       "    0.29131489992141724],\n",
       "   'val_loss': [5.078470833945076,\n",
       "    3.381886835472479,\n",
       "    2.5897072538987445,\n",
       "    2.2023288610196046,\n",
       "    2.0501651483729297,\n",
       "    1.8989004328096852,\n",
       "    1.786247753265402,\n",
       "    1.764242052370435,\n",
       "    1.7407021892954326,\n",
       "    1.7423296066867044]}),\n",
       " 'model_5': ('tanh',\n",
       "  0.4,\n",
       "  'adam',\n",
       "  'exp',\n",
       "  {'dense_consonant_accuracy': [0.6831881999969482,\n",
       "    0.7643314599990845,\n",
       "    0.7903246283531189,\n",
       "    0.7998433709144592,\n",
       "    0.8004627823829651,\n",
       "    0.803153932094574,\n",
       "    0.8001495003700256,\n",
       "    0.7976149916648865,\n",
       "    0.7952868938446045,\n",
       "    0.7908443808555603],\n",
       "   'dense_consonant_loss': [0.9248408675193787,\n",
       "    0.6768046617507935,\n",
       "    0.6099839210510254,\n",
       "    0.5884692072868347,\n",
       "    0.5844443440437317,\n",
       "    0.5776143670082092,\n",
       "    0.5837028622627258,\n",
       "    0.5904303193092346,\n",
       "    0.5997111797332764,\n",
       "    0.6127039790153503],\n",
       "   'dense_root_accuracy': [0.0519694909453392,\n",
       "    0.14945180714130402,\n",
       "    0.2300797402858734,\n",
       "    0.2711590528488159,\n",
       "    0.29243913292884827,\n",
       "    0.3072262704372406,\n",
       "    0.3168090581893921,\n",
       "    0.3176420331001282,\n",
       "    0.3070696294307709,\n",
       "    0.3066994249820709],\n",
       "   'dense_root_loss': [4.433084964752197,\n",
       "    3.5343527793884277,\n",
       "    3.045389175415039,\n",
       "    2.8344461917877197,\n",
       "    2.743638038635254,\n",
       "    2.674077272415161,\n",
       "    2.6321990489959717,\n",
       "    2.6527369022369385,\n",
       "    2.706040859222412,\n",
       "    2.708946466445923],\n",
       "   'dense_vowel_accuracy': [0.5690744519233704,\n",
       "    0.7083796262741089,\n",
       "    0.7367079854011536,\n",
       "    0.7379609942436218,\n",
       "    0.7457283139228821,\n",
       "    0.7467036843299866,\n",
       "    0.7473016977310181,\n",
       "    0.738010823726654,\n",
       "    0.7286416292190552,\n",
       "    0.7292823791503906],\n",
       "   'dense_vowel_loss': [1.248612880706787,\n",
       "    0.8641750812530518,\n",
       "    0.7963583469390869,\n",
       "    0.7907280921936035,\n",
       "    0.7677573561668396,\n",
       "    0.764240562915802,\n",
       "    0.7575225830078125,\n",
       "    0.7894336581230164,\n",
       "    0.8133227229118347,\n",
       "    0.8074884414672852],\n",
       "   'loss': [6.606540639109516,\n",
       "    5.07509260961138,\n",
       "    4.451884964024021,\n",
       "    4.213268436136942,\n",
       "    4.0959538512601315,\n",
       "    4.0157697032459705,\n",
       "    3.973498008544164,\n",
       "    4.032908889769693,\n",
       "    4.118940134481641,\n",
       "    4.129021250330857],\n",
       "   'lr': [0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513,\n",
       "    0.0010000000474974513],\n",
       "   'val_dense_consonant_accuracy': [0.785969078540802,\n",
       "    0.847750723361969,\n",
       "    0.8657600283622742,\n",
       "    0.8705162405967712,\n",
       "    0.8664536476135254,\n",
       "    0.8588981628417969,\n",
       "    0.8729439377784729,\n",
       "    0.8657600283622742,\n",
       "    0.8652893304824829,\n",
       "    0.8492618203163147],\n",
       "   'val_dense_consonant_loss': [0.5856812000274658,\n",
       "    0.4417532980442047,\n",
       "    0.3933160603046417,\n",
       "    0.3826565742492676,\n",
       "    0.4047029912471771,\n",
       "    0.3978138864040375,\n",
       "    0.3812042474746704,\n",
       "    0.4012116491794586,\n",
       "    0.411536306142807,\n",
       "    0.44006043672561646],\n",
       "   'val_dense_root_accuracy': [0.12809650599956512,\n",
       "    0.2789338231086731,\n",
       "    0.3678904175758362,\n",
       "    0.40559354424476624,\n",
       "    0.4050237834453583,\n",
       "    0.44290032982826233,\n",
       "    0.46586406230926514,\n",
       "    0.4213238060474396,\n",
       "    0.42996928095817566,\n",
       "    0.4062376022338867],\n",
       "   'val_dense_root_loss': [3.6064834594726562,\n",
       "    2.724623203277588,\n",
       "    2.3117361068725586,\n",
       "    2.159069299697876,\n",
       "    2.1445255279541016,\n",
       "    1.9956257343292236,\n",
       "    1.9241682291030884,\n",
       "    2.1064000129699707,\n",
       "    2.06792950630188,\n",
       "    2.1851003170013428],\n",
       "   'val_dense_vowel_accuracy': [0.7934998273849487,\n",
       "    0.831946074962616,\n",
       "    0.8572879433631897,\n",
       "    0.8494599461555481,\n",
       "    0.8592201471328735,\n",
       "    0.8651406764984131,\n",
       "    0.8623909950256348,\n",
       "    0.8474534153938293,\n",
       "    0.849534273147583,\n",
       "    0.8403686285018921],\n",
       "   'val_dense_vowel_loss': [0.6122921109199524,\n",
       "    0.5176458358764648,\n",
       "    0.4463450610637665,\n",
       "    0.4605182707309723,\n",
       "    0.4545946717262268,\n",
       "    0.4259546995162964,\n",
       "    0.43852102756500244,\n",
       "    0.480750173330307,\n",
       "    0.47446373105049133,\n",
       "    0.4927724003791809],\n",
       "   'val_loss': [4.804642104837945,\n",
       "    3.6842083414064906,\n",
       "    3.1517476966538887,\n",
       "    3.0018980587185538,\n",
       "    3.0036022907866404,\n",
       "    2.8191523928043156,\n",
       "    2.7439826623438086,\n",
       "    2.988316648780378,\n",
       "    2.953148071415312,\n",
       "    3.118041032843301]})}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train\n",
    "del x_test\n",
    "del y_train_root\n",
    "del y_test_root\n",
    "del y_train_vowel\n",
    "del y_test_vowel\n",
    "del y_train_consonant\n",
    "del y_test_consonant\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
